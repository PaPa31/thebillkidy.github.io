<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2019-05-28T10:30:21+00:00</updated><id>/feed.xml</id><title type="html">Xavier Geerinck - Blog</title><subtitle>My thoughts, tutorials and learnings</subtitle><entry><title type="html">Big Data Platform Comparisons</title><link href="/big-data-platforms-comparison" rel="alternate" type="text/html" title="Big Data Platform Comparisons" /><published>2019-05-27T09:00:00+00:00</published><updated>2019-05-27T09:00:00+00:00</updated><id>/big-data-platforms-comparison</id><content type="html" xml:base="/big-data-platforms-comparison">&lt;p&gt;Chosing a platform for doing your Big Data processing tasks is not an easy choice. At one side you want to be flexible and open, but at another you would like a stable and robust platform that can handle your critical business workloads.&lt;/p&gt;

&lt;p&gt;This is the reason that I decided to create a comparison of the different Big Data platforms from a &lt;strong&gt;Microsoft&lt;/strong&gt; perspective.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I am confident that other major cloud vendors such as Google and AWS, or even other vendors also have have excellent Big Data platform products, but seeing that I am not a specialist in these, I would like to keep it to the ones I am proficient in.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note 2:&lt;/strong&gt; This will also include a lot of assumptions to make the comparison as fair as possible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The products that we will be covering are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/databricks/&quot;&gt;Azure Databricks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/hdinsight/&quot;&gt;HDInsight&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/machine-learning-service/&quot;&gt;Machine Learning Services&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/open-source/cloudbreak/&quot;&gt;Cloudera Cloudbreak (old Hortonworks)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/spark/tree/master/resource-managers/kubernetes&quot;&gt;Apache Spark on Kubernetes (K8S)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I will not include a detailed overview of the services but rather a comparison. For a detailed overview, feel free to check the associated links for each service.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;assumptions&quot;&gt;Assumptions&lt;/h2&gt;

&lt;p&gt;As in any comparison, some assumptions were made. In this case the following assumptions were made:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1 Web Node was utilized where a web interface is required
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Size:&lt;/strong&gt; &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general#dv3-series-1&quot;&gt;D2v3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solutions:&lt;/strong&gt; Cloudera Cloudbreak&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;2 Head Nodes were utilized where required for HA purposes
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Size:&lt;/strong&gt; &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-general#av2-series&quot;&gt;A3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solutions:&lt;/strong&gt; HDInsight, Cloudera Cloudbreak&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;3 Worker Nodes were utilized
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Size:&lt;/strong&gt; &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-memory#dsv2-series-11-15&quot;&gt;D13v2&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solutions:&lt;/strong&gt; Azure Databricks, HDInsight, Machine Learning Services, Cloudera Cloudbreak, Apache Spark on Kubernetes (K8S)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;No Data Disks were selected&lt;/li&gt;
  &lt;li&gt;For Pausing enabled clusters, 8h was included (240h/mo) was taken, for others 24h (720h/mo)
    &lt;ul&gt;
      &lt;li&gt;Note: 8h pricing is also included in others, but has been wrapped with &lt;code class=&quot;highlighter-rouge&quot;&gt;()&lt;/code&gt; for clarity reasons. They can pause but extra work will be required to support this.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comparison-matrix&quot;&gt;Comparison Matrix&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;-&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Spark on K8S&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Azure Databricks&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;HDInsight&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Cloudera Cloudbreak&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Azure Machine Learning Services&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Multi Cloud&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes &lt;em&gt;(1)&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Deployment Model&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;IaaS / Half PaaS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PaaS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PaaS (with full cluster control)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;IaaS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PaaS, with integrated support for compute on ML Services, VMs, Databricks, HDI and K8S&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Auto Scale&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes (will require manual configuration)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes (preview)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes (on Machine Learning Compute or Databricks)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Compute Pause Support&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No (but scale-down yes and can be automated)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No (but scale-down yes, and can be automated)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Language Support&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Scala, Python, R, SQL, Java, &lt;a href=&quot;https://github.com/dotnet/spark&quot;&gt;.NET&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Scala, Python, R, SQL, Java&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Scala, Python, R, SQL, Java&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Scala, Python, R, SQL, Java&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Python &amp;amp; REST&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Notebook Support&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Scheduling Support&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes, through Oozie&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes, through Oozie&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes, Through Platform or SDK integration&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Tooling Re-training Required&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Server management through K8S&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Databricks Interface&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;HDP Components&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;HDP Components &amp;amp; Cloudbreak Interface&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;SDK Interface OR GUI Interface in Azure Portal&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;No&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Performance Gain Out-Of-The-Box&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;40%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;N/A&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;24h: $1,662.21&lt;br /&gt;(8h: $546.48)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;24h: $2,409.00&lt;br /&gt;8h: $803,88&lt;br /&gt;Note: perf increase added &lt;em&gt;(2)&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;24h: $2,084.00&lt;br /&gt;(8h: $685.15)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;24h: $2,100.36&lt;br /&gt;8h: $749.43&lt;br /&gt;+$375 license cost &lt;em&gt;(3)&lt;/em&gt; / mo&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Depends on K8S, HDI, Databricks VMs implementation&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;(1):&lt;/strong&gt; Multi Cloud since this is an offering that can be implemented through an SDK and is more on the Model Training and Operationalization part. Notebook support however has been included recently, making this a viable solution now. For Spark workloads, I however recommend to include another service with it.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(2):&lt;/strong&gt; Databricks offers an out of the box performance increase - see: &lt;a href=&quot;https://databricks.com/blog/2017/07/12/benchmarking-big-data-sql-platforms-in-the-cloud.html&quot;&gt;website1&lt;/a&gt; and &lt;a href=&quot;https://github.com/databricks/benchmarks&quot;&gt;website2&lt;/a&gt; for more details&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(3):&lt;/strong&gt; For enterprise support, licenses are required. See &lt;a href=&quot;https://hortonworks.com/services/support/enterprise/&quot;&gt;this website&lt;/a&gt; for more information. For our comparison, we took a price of $1.500 per license for only the worker nodes (so 3 worker nodes * $1.500 / 12 months). Exact pricing needs to be checked with Cloudera and this is purely indicative!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;More references can be found for the following products at these links:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HDInsight
    &lt;ul&gt;
      &lt;li&gt;AutoScale: &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-autoscale-clusters&quot;&gt;https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-autoscale-clusters&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Jupyter Notebook: &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-jupyter-notebook-kernels&quot;&gt;https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-jupyter-notebook-kernels&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Job Scheduling: &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-use-oozie-linux-mac#schedule-jobs&quot;&gt;https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-use-oozie-linux-mac#schedule-jobs&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Spark on K8S
    &lt;ul&gt;
      &lt;li&gt;Autoscale &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler&quot;&gt;https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler&lt;/a&gt; and &lt;a href=&quot;https://github.com/kedacore/keda&quot;&gt;https://github.com/kedacore/keda&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cloudbreak
    &lt;ul&gt;
      &lt;li&gt;Autoscale: &lt;a href=&quot;https://hortonworks.github.io/cloudbreak-documentation/latest/autoscaling/index.html&quot;&gt;https://hortonworks.github.io/cloudbreak-documentation/latest/autoscaling/index.html&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Notebooks: &lt;a href=&quot;https://community.hortonworks.com/articles/104453/using-zeppelin-with-spark-21-on-hdp-26-cluster-bui.html&quot;&gt;https://community.hortonworks.com/articles/104453/using-zeppelin-with-spark-21-on-hdp-26-cluster-bui.html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Azure Machine Learning Services
    &lt;ul&gt;
      &lt;li&gt;Compute Environments: &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets&quot;&gt;https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xavier Geerinck</name></author><category term="azure" /><category term="big-data" /><summary type="html">Chosing a platform for doing your Big Data processing tasks is not an easy choice. At one side you want to be flexible and open, but at another you would like a stable and robust platform that can handle your critical business workloads. This is the reason that I decided to create a comparison of the different Big Data platforms from a Microsoft perspective. Note: I am confident that other major cloud vendors such as Google and AWS, or even other vendors also have have excellent Big Data platform products, but seeing that I am not a specialist in these, I would like to keep it to the ones I am proficient in. Note 2: This will also include a lot of assumptions to make the comparison as fair as possible. The products that we will be covering are: Azure Databricks HDInsight Machine Learning Services Cloudera Cloudbreak (old Hortonworks) Apache Spark on Kubernetes (K8S) Note: I will not include a detailed overview of the services but rather a comparison. For a detailed overview, feel free to check the associated links for each service. Assumptions As in any comparison, some assumptions were made. In this case the following assumptions were made: 1 Web Node was utilized where a web interface is required Size: D2v3 Solutions: Cloudera Cloudbreak 2 Head Nodes were utilized where required for HA purposes Size: A3 Solutions: HDInsight, Cloudera Cloudbreak 3 Worker Nodes were utilized Size: D13v2 Solutions: Azure Databricks, HDInsight, Machine Learning Services, Cloudera Cloudbreak, Apache Spark on Kubernetes (K8S) No Data Disks were selected For Pausing enabled clusters, 8h was included (240h/mo) was taken, for others 24h (720h/mo) Note: 8h pricing is also included in others, but has been wrapped with () for clarity reasons. They can pause but extra work will be required to support this. Comparison Matrix - Spark on K8S Azure Databricks HDInsight Cloudera Cloudbreak Azure Machine Learning Services Multi Cloud Yes Yes No Yes Yes (1) Deployment Model IaaS / Half PaaS PaaS PaaS (with full cluster control) IaaS PaaS, with integrated support for compute on ML Services, VMs, Databricks, HDI and K8S Auto Scale Yes (will require manual configuration) Yes Yes (preview) Yes Yes (on Machine Learning Compute or Databricks) Compute Pause Support No (but scale-down yes and can be automated) Yes No (but scale-down yes, and can be automated) Yes Yes Language Support Scala, Python, R, SQL, Java, .NET Scala, Python, R, SQL, Java Scala, Python, R, SQL, Java Scala, Python, R, SQL, Java Python &amp;amp; REST Notebook Support No Yes Yes Yes Yes Scheduling Support No Yes Yes, through Oozie Yes, through Oozie Yes, Through Platform or SDK integration Tooling Re-training Required Server management through K8S Databricks Interface HDP Components HDP Components &amp;amp; Cloudbreak Interface SDK Interface OR GUI Interface in Azure Portal Extensibility No No Yes Yes Yes Performance Gain Out-Of-The-Box 0% 40% 0% 0% N/A Cost 24h: $1,662.21(8h: $546.48) 24h: $2,409.008h: $803,88Note: perf increase added (2) 24h: $2,084.00(8h: $685.15) 24h: $2,100.368h: $749.43+$375 license cost (3) / mo Depends on K8S, HDI, Databricks VMs implementation Notes: (1): Multi Cloud since this is an offering that can be implemented through an SDK and is more on the Model Training and Operationalization part. Notebook support however has been included recently, making this a viable solution now. For Spark workloads, I however recommend to include another service with it. (2): Databricks offers an out of the box performance increase - see: website1 and website2 for more details (3): For enterprise support, licenses are required. See this website for more information. For our comparison, we took a price of $1.500 per license for only the worker nodes (so 3 worker nodes * $1.500 / 12 months). Exact pricing needs to be checked with Cloudera and this is purely indicative! References More references can be found for the following products at these links: HDInsight AutoScale: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-autoscale-clusters Jupyter Notebook: https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-jupyter-notebook-kernels Job Scheduling: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-use-oozie-linux-mac#schedule-jobs Spark on K8S Autoscale https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler and https://github.com/kedacore/keda Cloudbreak Autoscale: https://hortonworks.github.io/cloudbreak-documentation/latest/autoscaling/index.html Notebooks: https://community.hortonworks.com/articles/104453/using-zeppelin-with-spark-21-on-hdp-26-cluster-bui.html Azure Machine Learning Services Compute Environments: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets</summary></entry><entry><title type="html">Part 1 - Manage, Connect and Deploy our simulators to our Edge Devices with IoT Hub</title><link href="/iot-edge-part1" rel="alternate" type="text/html" title="Part 1 - Manage, Connect and Deploy our simulators to our Edge Devices with IoT Hub" /><published>2019-05-20T09:00:00+00:00</published><updated>2019-05-20T09:00:00+00:00</updated><id>/iot-edge-part1</id><content type="html" xml:base="/iot-edge-part1">&lt;!-- &gt; This is Part 1 in the Iot Edge series, view the [main article](/iot-edge) or go the [part 2](/iot-edge-part2) to continue. --&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is Part 1 in the Iot Edge series, view the &lt;a href=&quot;/iot-edge&quot;&gt;main article&lt;/a&gt;. Part 2 is currently under construction and will follow soon.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/architecture2.png&quot; alt=&quot;/assets/images/posts/iot-edge/architecture2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looking at our architecture, we need to be able to connect out devices and get some interesting output from them before we can actually do something with them. In this first part we will be mainly focusing on doing just that - connecting our devices and sending data to our IoT Hub resource.&lt;/p&gt;

&lt;p&gt;Therefor in this Part we have the following &lt;strong&gt;prerequisities:&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note for my variables I used the following:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;YOUR_IOTHUB_NAME = xavier-iothub&lt;/li&gt;
    &lt;li&gt;YOUR_DEVICE_ID = xavier-device-1&lt;/li&gt;
    &lt;li&gt;YOUR_EDGE_VM = xavier-edge-1&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;IoT Hub - Connect and manage your devices
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;az iot hub create --resource-group DEMO-IoTEdge --name {YOUR_IOTHUB_NAME} --sku F1&lt;/code&gt; will create a &lt;em&gt;free&lt;/em&gt; iot hub (limits: 8k messages per day and 500 registered devices)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Azure Shell + IoT Cli Extension
    &lt;ul&gt;
      &lt;li&gt;Note: Easy way is utilizing &lt;a href=&quot;https://shell.azure.com&quot;&gt;https://shell.azure.com&lt;/a&gt; and run &lt;code class=&quot;highlighter-rouge&quot;&gt;az extension add --name azure-cli-iot-ext&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Azure Edge Runtime on the device
    &lt;ul&gt;
      &lt;li&gt;Linux x64: https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux&lt;/li&gt;
      &lt;li&gt;Linux ARM: https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux-arm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;An ARM IoT Device (we use ARM because it might give compatibility issues, but we will most likely have ARM devices in the field)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;registering-a-device&quot;&gt;Registering a Device&lt;/h2&gt;

&lt;h3 id=&quot;creating-a-simulation-device&quot;&gt;Creating a simulation device&lt;/h3&gt;

&lt;p&gt;Checking &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/iot-edge/support#operating-systems&quot;&gt;IoT Edge Supported Devices&lt;/a&gt; showed me that Ubuntu 18.04 is supported on ARM. However since I didn’t have access to a ARM device on the moment of writing, I went with deploying a VM on Azure, which is easily done through the marketplace: &lt;a href=&quot;https://azuremarketplace.microsoft.com/marketplace/apps/microsoft_iot_edge.iot_edge_vm_ubuntu&quot;&gt;https://azuremarketplace.microsoft.com/marketplace/apps/microsoft_iot_edge.iot_edge_vm_ubuntu&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;az vm create &lt;span class=&quot;nt&quot;&gt;--resource-group&lt;/span&gt; DEMO-IoTEdge &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; xavier-edge-1 &lt;span class=&quot;nt&quot;&gt;--image&lt;/span&gt; microsoft_iot_edge:iot_edge_vm_ubuntu:ubuntu_1604_edgeruntimeonly:latest &lt;span class=&quot;nt&quot;&gt;--admin-username&lt;/span&gt; xavier &lt;span class=&quot;nt&quot;&gt;--ssh-key-values&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;YOUR_SSH_KEY&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--size&lt;/span&gt; Standard_B1ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: if you are installing on an ARM, feel free to follow the guide at: &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux-arm&quot;&gt;https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux-arm&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;creating-an-iot-edge-device-id&quot;&gt;Creating an IoT Edge Device ID&lt;/h3&gt;

&lt;p&gt;Once our prerequisites are done, we can start adding our devices. For this run: &lt;code class=&quot;highlighter-rouge&quot;&gt;az iot hub device-identity create --hub-name {YOUR_IOTHUB_NAME} --device-id {YOUR_DEVICE_ID} --edge-enabled&lt;/code&gt; which will create an edge-enabled device. This will return something like this:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;authentication&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;symmetricKey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;primaryKey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{MASKED}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;secondaryKey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{MASKED}&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;sas&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;x509Thumbprint&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;primaryThumbprint&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;secondaryThumbprint&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;capabilities&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;iotEdge&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cloudToDeviceMessageCount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;connectionState&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Disconnected&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;connectionStateUpdatedTime&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0001-01-01T00:00:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;deviceId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;xavier-device-1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;deviceScope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ms-azure-iot-edge://xavier-device-1-{ID}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etag&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{ETAG}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;generationId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{ID}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lastActivityTime&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0001-01-01T00:00:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;enabled&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;statusReason&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;statusUpdatedTime&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0001-01-01T00:00:00&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;connecting-our-iot-edge-device-to-iot-hub&quot;&gt;Connecting our IoT Edge Device to IoT Hub&lt;/h2&gt;

&lt;p&gt;Once we deployed this VM, we can now configure our IoT Edge by getting our IoT Hub connection string and running a shell command which is available in the image.&lt;/p&gt;

&lt;p&gt;To get our connection string we can run:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;az iot hub device-identity show-connection-string &lt;span class=&quot;nt&quot;&gt;--device-id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;YOUR_DEVICE_ID&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--hub-name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;YOUR_IOTHUB_NAME&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which will return something such as:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;connectionString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;HostName={YOUR_IOTHUB}.azure-devices.net;DeviceId={YOUR_DEVICE_ID};SharedAccessKey={ACCESS_KEY}&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we can run the following script which was pre-deployed on our Edge Device through the Marketplace image, that will configure our edge device:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;az vm run-command invoke &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; Demo-IoTEdge &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;YOUR_EDGE_VM&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--command-id&lt;/span&gt; RunShellScript &lt;span class=&quot;nt&quot;&gt;--script&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/iotedge/configedge.sh '{YOUR_DEVICE_CONNECTION_STRING}'&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which should show the following when executed successfully:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;xavier@Azure:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;az vm run-command invoke &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; Demo-IoTEdge &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; xavier-edge-1 &lt;span class=&quot;nt&quot;&gt;--command-id&lt;/span&gt; RunShellScript &lt;span class=&quot;nt&quot;&gt;--script&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/iotedge/configedge.sh 'HostName=xavier-iothub.azure-devices.net;DeviceId=xavier-device-1;SharedAccessKey={YOUR_DEVICE_ACCCESS_KEY}'&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s2&quot;&gt;&quot;value&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;code&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;ProvisioningState/succeeded&quot;&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;displayStatus&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Provisioning succeeded&quot;&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;level&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Info&quot;&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;message&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Enable succeeded: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;[stdout]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; Wed May 22 13:24:14 UTC 2019 Connection string set to HostName=xavier-iothub.azure-devices.net;DeviceId=xavier-device-1;SharedAccessKey={YOUR_DEVICE_ACCCESS_KEY}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;[stderr]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;time&quot;&lt;/span&gt;: null
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can now check if IoT Edge is running by SSHing on the machine and executing &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo systemctl status iotedge&lt;/code&gt;
&lt;strong&gt;Interesting Commands:&lt;/strong&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;journalctl -u iotedge&lt;/code&gt; - Check logs, &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo iotedge list&lt;/code&gt; - Show modules running&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;creating-our-edge-devices-echo-module&quot;&gt;Creating our Edge Device’s Echo Module&lt;/h2&gt;

&lt;p&gt;For testing purposes, we want to create a small container that echos the current time every 2 seconds to IoT Hub. To do this we follow a few steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Command Palette (ctrl + p):&lt;/strong&gt; Azure: Sign In&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Command Palette (ctrl + p):&lt;/strong&gt; Azure IoT Edge: New IoT Edge solution
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Path:&lt;/strong&gt; /home/xavier/iot-edge/&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; EdgeSolutionCameraFilter&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Module Template:&lt;/strong&gt; C# Module&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Module Name:&lt;/strong&gt; EchoModule (our demo container for now)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Docker Repository:&lt;/strong&gt; xavierregistry.azurecr.io/echomodule&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: for more information and details, check &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/iot-edge/tutorial-csharp-module&quot;&gt;https://docs.microsoft.com/en-us/azure/iot-edge/tutorial-csharp-module&lt;/a&gt; which goes through the steps of creating a temperature model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note 2: I didn’t have docker installed on my machine. We can however easily work around this by utilizing a remote Linux VM Machine and use &lt;a href=&quot;https://code.visualstudio.com/docs/remote/remote-overview&quot;&gt;VS Code Remote-SSH&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once we did that, we will see the following boilerplate code created once we open our folder.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This boilerplate code creates a module that will play back our input on the output channel. To make this clearer, I renamed &lt;code class=&quot;highlighter-rouge&quot;&gt;input1&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;input-echo&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;output1&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;output-echo&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation-2.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another thing I did is to add a timer that will send a message every 30 seconds to make it clear that it is actually doing something and that we don’t necessarily have to send something to it ;) The code I used for that:&lt;/p&gt;

&lt;div class=&quot;language-csharp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Register a Timer that will send every X seconds&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myTimer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Timers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Elapsed&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Timers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ElapsedEventHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Timers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ElapsedEventArgs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ToString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UTF8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;GetBytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$&quot;Sending event at &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ioTHubModuleClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;SendEventAsync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;output&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Interval&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Every 30 seconds&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Enabled&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation-3.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation-3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A last thing we now have to do is to remove a few lines from our &lt;code class=&quot;highlighter-rouge&quot;&gt;deployment.template.json&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;deployment.template.debug.json&lt;/code&gt; file in the root folder:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s2&quot;&gt;&quot;sensorToEchoModule&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;FROM /messages/modules/tempSensor/outputs/temperatureOutput INTO BrokeredEndpoint(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/modules/EchoModule/inputs/input1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And some lines that deploy another module that we don’t need&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s2&quot;&gt;&quot;tempSensor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;version&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;docker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;running&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;restartPolicy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;always&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;settings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mcr.microsoft.com/azureiotedge-simulated-temperature-sensor:1.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;createOptions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{}&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we are ready to build, publish and finally deploy our edge module.&lt;/p&gt;

&lt;h2 id=&quot;building-publishing--deploying-the-edge-module&quot;&gt;Building, Publishing &amp;amp; Deploying the Edge Module&lt;/h2&gt;

&lt;h3 id=&quot;building-and-publishing-our-edge-module&quot;&gt;Building and Publishing our Edge Module&lt;/h3&gt;

&lt;p&gt;We can now easily build and publish our Edge Module by right-clicking our &lt;code class=&quot;highlighter-rouge&quot;&gt;deployment.template.json&lt;/code&gt; and selecting “Build and Push Iot Edge Solution”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation-4.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-creation-4.png&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For me this failed due to permission issues on my Linux machine, however when you have the terminal open you can just press the up arrow and add &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt; in the front. 
&lt;strong&gt;Hint:&lt;/strong&gt; ctrl + a jumps to the beginning of a line&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will now build and push our solution, resulting in:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Docker container is building&lt;/span&gt;
Step 1/12 : FROM microsoft/dotnet:2.1-sdk AS build-env
2.1-sdk: Pulling from microsoft/dotnet
c5e155d5a1d1: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;221d80d00ae9: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;4250b3117dca: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;3b7ca19181b2: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;5980daa97e3c: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;7cbae962589c: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;4ab425e558b6: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;Digest: sha256:481a526515bd95f7ecbe866b99ddac6130da3402e8e4fb09712123393d3f1475
Status: Downloaded newer image &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;microsoft/dotnet:2.1-sdk
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 511c1f563ce6
Step 2/12 : WORKDIR /app
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;ed3388ecf107
Removing intermediate container ed3388ecf107
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; e8033981828f
Step 3/12 : COPY &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.csproj ./
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 4614b845cc5d
Step 4/12 : RUN dotnet restore &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;2db5ed302e26  Restore completed &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;3.24 sec &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; /app/EchoModule.csproj.
Removing intermediate container 2db5ed302e26
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; b74b9ac5490b
Step 5/12 : COPY &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; ./
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 8132d7ecea0d
 Step 6/12 : RUN dotnet publish &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; Release &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; out
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;62098984d63d
Microsoft &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;R&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Build Engine version 16.1.76+g14b0a930a7 &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; .NET Core
Copyright &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;C&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Microsoft Corporation. All rights reserved.

  Restore completed &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;485.11 ms &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; /app/EchoModule.csproj.
  EchoModule -&amp;gt; /app/bin/Release/netcoreapp2.1/EchoModule.dll
  EchoModule -&amp;gt; /app/out/
Removing intermediate container 62098984d63d
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 46899da4cedb
Step 7/12 : FROM microsoft/dotnet:2.1-runtime-stretch-slim
2.1-runtime-stretch-slim: Pulling from microsoft/dotnet
743f2d6c1f65: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;074da88b8de0: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;ac831735b47a: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;625946e33cc4: Pull &lt;span class=&quot;nb&quot;&gt;complete 
&lt;/span&gt;Digest: sha256:5ff2b0f6e69b44f6404d46445be34408551331429d5a84b667cfee49ebd8117d
Status: Downloaded newer image &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;microsoft/dotnet:2.1-runtime-stretch-slim
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; f7da44fabfad
Step 8/12 : WORKDIR /app
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;b999e9d179aa
Removing intermediate container b999e9d179aa
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 247b2ac0a988
Step 9/12 : COPY &lt;span class=&quot;nt&quot;&gt;--from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;build-env /app/out ./
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; ef30f581b39d
Step 10/12 : RUN useradd &lt;span class=&quot;nt&quot;&gt;-ms&lt;/span&gt; /bin/bash moduleuser
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;172a5e40a83e
Removing intermediate container 172a5e40a83e
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; dc3691450b75
Step 11/12 : USER moduleuser
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;c71d5ab2fc77
Removing intermediate container c71d5ab2fc77
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; d4798c0654e7
Step 12/12 : ENTRYPOINT &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dotnet&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;EchoModule.dll&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;547f0facbdd8
Removing intermediate container 547f0facbdd8
 &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 114a7cc96b50
Successfully built 114a7cc96b50
Successfully tagged xavierregistry.azurecr.io/echomodule:0.0.1-amd64

&lt;span class=&quot;c&quot;&gt;# Pushing it&lt;/span&gt;
The push refers to repository &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xavierregistry.azurecr.io/echomodule]
11e1e4b905fe: Pushed 
a0d529ad3f07: Pushed 
f081219e5aa6: Pushed 
be1595c6dfc4: Pushed 
ecf7942d9af2: Pushed 
ea4e5356527d: Pushed 
6270adb5794c: Pushed 
0.0.1-amd64: digest: sha256:7021323942c2323adb48d17ec73b00e69ec19216c816de59e2eb6e9a0b3f682c size: 1789
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;deploying-our-edge-module&quot;&gt;Deploying our Edge Module&lt;/h3&gt;

&lt;p&gt;Now that our module is created and pushed to our repository, we can now push it to our Edge Module. For this, simply right-click on our device and select “Create Deployment for Single Device”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-deploy.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-deploy.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-deploy-2.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-deploy-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This will open up our output and show:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Edge] Start deployment to device &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xavier-device-1]
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Edge] Deployment succeeded.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When we open up our device now, we can see that under modules we have an extra module deployed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/iothub-echo-module-deploy-3.png&quot; alt=&quot;/assets/images/posts/iot-edge/iothub-echo-module-deploy-3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;testing-our-deployment&quot;&gt;Testing our Deployment&lt;/h2&gt;

&lt;p&gt;To monitor our device, we can now go to our devices and select “Start Monitoring Built-In Event Endpoint” which will open a logger for us. When we did this, we will now after a few seconds see:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;IoTHubMonitor] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;5:59:27 PM] Message received from &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xavier-device-1/EchoModule]:
&lt;span class=&quot;s2&quot;&gt;&quot;Sending event at 05/24/2019 17:59&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For our Echo module, we can now send a C2D message (Cloud to Device), we do this by Right-Clicking our device again and selecting “Send D2C Message to IoTHub” and entering our message.&lt;/p&gt;

&lt;p&gt;When everything goes well we will now see the following in our Device Event Log:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;D2CMessage] Sending message to &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;IoT Hub] ...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;IoTHubMonitor] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;6:02:36 PM] Message received from &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;xavier-device-1]:
&lt;span class=&quot;s2&quot;&gt;&quot;Hello World&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We now created our first initial module, so let’s get started for real now and work on &lt;a href=&quot;/iot-edge-part2&quot;&gt;creating our AI Edge Module in Part 2&lt;/a&gt;!&lt;/p&gt;</content><author><name>Xavier Geerinck</name></author><category term="azure" /><category term="coding-javascript" /><summary type="html">This is Part 1 in the Iot Edge series, view the main article. Part 2 is currently under construction and will follow soon. Looking at our architecture, we need to be able to connect out devices and get some interesting output from them before we can actually do something with them. In this first part we will be mainly focusing on doing just that - connecting our devices and sending data to our IoT Hub resource. Therefor in this Part we have the following prerequisities: Note for my variables I used the following: YOUR_IOTHUB_NAME = xavier-iothub YOUR_DEVICE_ID = xavier-device-1 YOUR_EDGE_VM = xavier-edge-1 Prerequisites IoT Hub - Connect and manage your devices az iot hub create --resource-group DEMO-IoTEdge --name {YOUR_IOTHUB_NAME} --sku F1 will create a free iot hub (limits: 8k messages per day and 500 registered devices) Azure Shell + IoT Cli Extension Note: Easy way is utilizing https://shell.azure.com and run az extension add --name azure-cli-iot-ext Azure Edge Runtime on the device Linux x64: https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux Linux ARM: https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux-arm An ARM IoT Device (we use ARM because it might give compatibility issues, but we will most likely have ARM devices in the field) Registering a Device Creating a simulation device Checking IoT Edge Supported Devices showed me that Ubuntu 18.04 is supported on ARM. However since I didn’t have access to a ARM device on the moment of writing, I went with deploying a VM on Azure, which is easily done through the marketplace: https://azuremarketplace.microsoft.com/marketplace/apps/microsoft_iot_edge.iot_edge_vm_ubuntu. az vm create --resource-group DEMO-IoTEdge --name xavier-edge-1 --image microsoft_iot_edge:iot_edge_vm_ubuntu:ubuntu_1604_edgeruntimeonly:latest --admin-username xavier --ssh-key-values &quot;YOUR_SSH_KEY&quot; --size Standard_B1ms Note: if you are installing on an ARM, feel free to follow the guide at: https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux-arm Creating an IoT Edge Device ID Once our prerequisites are done, we can start adding our devices. For this run: az iot hub device-identity create --hub-name {YOUR_IOTHUB_NAME} --device-id {YOUR_DEVICE_ID} --edge-enabled which will create an edge-enabled device. This will return something like this: { &quot;authentication&quot;: { &quot;symmetricKey&quot;: { &quot;primaryKey&quot;: &quot;{MASKED}&quot;, &quot;secondaryKey&quot;: &quot;{MASKED}&quot; }, &quot;type&quot;: &quot;sas&quot;, &quot;x509Thumbprint&quot;: { &quot;primaryThumbprint&quot;: null, &quot;secondaryThumbprint&quot;: null } }, &quot;capabilities&quot;: { &quot;iotEdge&quot;: true }, &quot;cloudToDeviceMessageCount&quot;: 0, &quot;connectionState&quot;: &quot;Disconnected&quot;, &quot;connectionStateUpdatedTime&quot;: &quot;0001-01-01T00:00:00&quot;, &quot;deviceId&quot;: &quot;xavier-device-1&quot;, &quot;deviceScope&quot;: &quot;ms-azure-iot-edge://xavier-device-1-{ID}&quot;, &quot;etag&quot;: &quot;{ETAG}&quot;, &quot;generationId&quot;: &quot;{ID}&quot;, &quot;lastActivityTime&quot;: &quot;0001-01-01T00:00:00&quot;, &quot;status&quot;: &quot;enabled&quot;, &quot;statusReason&quot;: null, &quot;statusUpdatedTime&quot;: &quot;0001-01-01T00:00:00&quot; } Connecting our IoT Edge Device to IoT Hub Once we deployed this VM, we can now configure our IoT Edge by getting our IoT Hub connection string and running a shell command which is available in the image. To get our connection string we can run: az iot hub device-identity show-connection-string --device-id {YOUR_DEVICE_ID} --hub-name {YOUR_IOTHUB_NAME} Which will return something such as: { &quot;connectionString&quot;: &quot;HostName={YOUR_IOTHUB}.azure-devices.net;DeviceId={YOUR_DEVICE_ID};SharedAccessKey={ACCESS_KEY}&quot; } Now we can run the following script which was pre-deployed on our Edge Device through the Marketplace image, that will configure our edge device: az vm run-command invoke -g Demo-IoTEdge -n {YOUR_EDGE_VM} --command-id RunShellScript --script &quot;/etc/iotedge/configedge.sh '{YOUR_DEVICE_CONNECTION_STRING}'&quot; Which should show the following when executed successfully: xavier@Azure:~$ az vm run-command invoke -g Demo-IoTEdge -n xavier-edge-1 --command-id RunShellScript --script &quot;/etc/iotedge/configedge.sh 'HostName=xavier-iothub.azure-devices.net;DeviceId=xavier-device-1;SharedAccessKey={YOUR_DEVICE_ACCCESS_KEY}'&quot; { &quot;value&quot;: [ { &quot;code&quot;: &quot;ProvisioningState/succeeded&quot;, &quot;displayStatus&quot;: &quot;Provisioning succeeded&quot;, &quot;level&quot;: &quot;Info&quot;, &quot;message&quot;: &quot;Enable succeeded: \n[stdout]\n Wed May 22 13:24:14 UTC 2019 Connection string set to HostName=xavier-iothub.azure-devices.net;DeviceId=xavier-device-1;SharedAccessKey={YOUR_DEVICE_ACCCESS_KEY}\n\n[stderr]\n&quot;, &quot;time&quot;: null } ] } Note: You can now check if IoT Edge is running by SSHing on the machine and executing sudo systemctl status iotedge Interesting Commands: journalctl -u iotedge - Check logs, sudo iotedge list - Show modules running Creating our Edge Device’s Echo Module For testing purposes, we want to create a small container that echos the current time every 2 seconds to IoT Hub. To do this we follow a few steps: Command Palette (ctrl + p): Azure: Sign In Command Palette (ctrl + p): Azure IoT Edge: New IoT Edge solution Path: /home/xavier/iot-edge/ Solution: EdgeSolutionCameraFilter Module Template: C# Module Module Name: EchoModule (our demo container for now) Docker Repository: xavierregistry.azurecr.io/echomodule Note: for more information and details, check https://docs.microsoft.com/en-us/azure/iot-edge/tutorial-csharp-module which goes through the steps of creating a temperature model. Note 2: I didn’t have docker installed on my machine. We can however easily work around this by utilizing a remote Linux VM Machine and use VS Code Remote-SSH Once we did that, we will see the following boilerplate code created once we open our folder. This boilerplate code creates a module that will play back our input on the output channel. To make this clearer, I renamed input1 to input-echo and output1 to output-echo. Another thing I did is to add a timer that will send a message every 30 seconds to make it clear that it is actually doing something and that we don’t necessarily have to send something to it ;) The code I used for that: // Register a Timer that will send every X seconds var myTimer = new System.Timers.Timer(); myTimer.Elapsed += new System.Timers.ElapsedEventHandler((object source, System.Timers.ElapsedEventArgs e) =&amp;gt; { var now = DateTime.Now.ToString(&quot;g&quot;); var message = new Message(Encoding.UTF8.GetBytes($&quot;Sending event at {now}&quot;)); ioTHubModuleClient.SendEventAsync(&quot;output&quot;, message); }); myTimer.Interval = 30 * 1000; // Every 30 seconds myTimer.Enabled = true; A last thing we now have to do is to remove a few lines from our deployment.template.json and deployment.template.debug.json file in the root folder: &quot;sensorToEchoModule&quot;: &quot;FROM /messages/modules/tempSensor/outputs/temperatureOutput INTO BrokeredEndpoint(\&quot;/modules/EchoModule/inputs/input1\&quot;)&quot; And some lines that deploy another module that we don’t need &quot;tempSensor&quot;: { &quot;version&quot;: &quot;1.0&quot;, &quot;type&quot;: &quot;docker&quot;, &quot;status&quot;: &quot;running&quot;, &quot;restartPolicy&quot;: &quot;always&quot;, &quot;settings&quot;: { &quot;image&quot;: &quot;mcr.microsoft.com/azureiotedge-simulated-temperature-sensor:1.0&quot;, &quot;createOptions&quot;: &quot;{}&quot; } }, Now we are ready to build, publish and finally deploy our edge module. Building, Publishing &amp;amp; Deploying the Edge Module Building and Publishing our Edge Module We can now easily build and publish our Edge Module by right-clicking our deployment.template.json and selecting “Build and Push Iot Edge Solution” Note: For me this failed due to permission issues on my Linux machine, however when you have the terminal open you can just press the up arrow and add sudo in the front. Hint: ctrl + a jumps to the beginning of a line This will now build and push our solution, resulting in: # Docker container is building Step 1/12 : FROM microsoft/dotnet:2.1-sdk AS build-env 2.1-sdk: Pulling from microsoft/dotnet c5e155d5a1d1: Pull complete 221d80d00ae9: Pull complete 4250b3117dca: Pull complete 3b7ca19181b2: Pull complete 5980daa97e3c: Pull complete 7cbae962589c: Pull complete 4ab425e558b6: Pull complete Digest: sha256:481a526515bd95f7ecbe866b99ddac6130da3402e8e4fb09712123393d3f1475 Status: Downloaded newer image for microsoft/dotnet:2.1-sdk ---&amp;gt; 511c1f563ce6 Step 2/12 : WORKDIR /app ---&amp;gt; Running in ed3388ecf107 Removing intermediate container ed3388ecf107 ---&amp;gt; e8033981828f Step 3/12 : COPY *.csproj ./ ---&amp;gt; 4614b845cc5d Step 4/12 : RUN dotnet restore ---&amp;gt; Running in 2db5ed302e26 Restore completed in 3.24 sec for /app/EchoModule.csproj. Removing intermediate container 2db5ed302e26 ---&amp;gt; b74b9ac5490b Step 5/12 : COPY . ./ ---&amp;gt; 8132d7ecea0d Step 6/12 : RUN dotnet publish -c Release -o out ---&amp;gt; Running in 62098984d63d Microsoft (R) Build Engine version 16.1.76+g14b0a930a7 for .NET Core Copyright (C) Microsoft Corporation. All rights reserved. Restore completed in 485.11 ms for /app/EchoModule.csproj. EchoModule -&amp;gt; /app/bin/Release/netcoreapp2.1/EchoModule.dll EchoModule -&amp;gt; /app/out/ Removing intermediate container 62098984d63d ---&amp;gt; 46899da4cedb Step 7/12 : FROM microsoft/dotnet:2.1-runtime-stretch-slim 2.1-runtime-stretch-slim: Pulling from microsoft/dotnet 743f2d6c1f65: Pull complete 074da88b8de0: Pull complete ac831735b47a: Pull complete 625946e33cc4: Pull complete Digest: sha256:5ff2b0f6e69b44f6404d46445be34408551331429d5a84b667cfee49ebd8117d Status: Downloaded newer image for microsoft/dotnet:2.1-runtime-stretch-slim ---&amp;gt; f7da44fabfad Step 8/12 : WORKDIR /app ---&amp;gt; Running in b999e9d179aa Removing intermediate container b999e9d179aa ---&amp;gt; 247b2ac0a988 Step 9/12 : COPY --from=build-env /app/out ./ ---&amp;gt; ef30f581b39d Step 10/12 : RUN useradd -ms /bin/bash moduleuser ---&amp;gt; Running in 172a5e40a83e Removing intermediate container 172a5e40a83e ---&amp;gt; dc3691450b75 Step 11/12 : USER moduleuser ---&amp;gt; Running in c71d5ab2fc77 Removing intermediate container c71d5ab2fc77 ---&amp;gt; d4798c0654e7 Step 12/12 : ENTRYPOINT [&quot;dotnet&quot;, &quot;EchoModule.dll&quot;] ---&amp;gt; Running in 547f0facbdd8 Removing intermediate container 547f0facbdd8 ---&amp;gt; 114a7cc96b50 Successfully built 114a7cc96b50 Successfully tagged xavierregistry.azurecr.io/echomodule:0.0.1-amd64 # Pushing it The push refers to repository [xavierregistry.azurecr.io/echomodule] 11e1e4b905fe: Pushed a0d529ad3f07: Pushed f081219e5aa6: Pushed be1595c6dfc4: Pushed ecf7942d9af2: Pushed ea4e5356527d: Pushed 6270adb5794c: Pushed 0.0.1-amd64: digest: sha256:7021323942c2323adb48d17ec73b00e69ec19216c816de59e2eb6e9a0b3f682c size: 1789 Deploying our Edge Module Now that our module is created and pushed to our repository, we can now push it to our Edge Module. For this, simply right-click on our device and select “Create Deployment for Single Device” This will open up our output and show: [Edge] Start deployment to device [xavier-device-1] [Edge] Deployment succeeded. When we open up our device now, we can see that under modules we have an extra module deployed. Testing our Deployment To monitor our device, we can now go to our devices and select “Start Monitoring Built-In Event Endpoint” which will open a logger for us. When we did this, we will now after a few seconds see: [IoTHubMonitor] [5:59:27 PM] Message received from [xavier-device-1/EchoModule]: &quot;Sending event at 05/24/2019 17:59&quot; For our Echo module, we can now send a C2D message (Cloud to Device), we do this by Right-Clicking our device again and selecting “Send D2C Message to IoTHub” and entering our message. When everything goes well we will now see the following in our Device Event Log: [D2CMessage] Sending message to [IoT Hub] ... [IoTHubMonitor] [6:02:36 PM] Message received from [xavier-device-1]: &quot;Hello World&quot; Conclusion We now created our first initial module, so let’s get started for real now and work on creating our AI Edge Module in Part 2!</summary></entry><entry><title type="html">Creating an Internet Of Things (IoT) Edge Deployment</title><link href="/iot-edge" rel="alternate" type="text/html" title="Creating an Internet Of Things (IoT) Edge Deployment" /><published>2019-05-20T09:00:00+00:00</published><updated>2019-05-20T09:00:00+00:00</updated><id>/iot-edge</id><content type="html" xml:base="/iot-edge">&lt;p&gt;The Internet-Of-Things (IoT) is currently in full roll-out around the world and will only grow with the deployment of 5G, enabling new use cases and collecting more data than ever seen before. An important aspect of this is not only managing the data that you collect, but also correctly filtering and reducing the latency that you experience on-premise. It is not accepted that it takes 10 seconds round-trip from a container ship in the middle of the atlantic ocean, if you need a response for every image of a camera feed at 24fps.&lt;/p&gt;

&lt;p&gt;A way to solve this is by utilizing edge deployments. Edge deployments allow you to create your model in a scalable environment (cloud) and deploy these to the edge devices. Which can then utilize this model, filter the needed data and send just this data back when the connection is re-established.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Interesting use cases&lt;/strong&gt; for example are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Image processing from live video feeds (drones, street cameras, train tracks, …)
    &lt;ul&gt;
      &lt;li&gt;Just think about streaming at 24fps, including your model inference and including the network round-trip&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dongles in cars, sending the captured data from its CAN-bus
    &lt;ul&gt;
      &lt;li&gt;If a car sends at 1Hz, what is your captured data rate? It’s &lt;a href=&quot;https://newsroom.intel.com/editorials/self-driving-cars-big-meaning-behind-one-number-4-terabytes/&quot;&gt;predicted&lt;/a&gt; that self-driving cars will consume about 4Tb every 1.5 hours!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So how can we solve this technical wise? Well you’d be happy to know that currently we have all the tools in place to actually accomplish this on-edge computing already!&lt;/p&gt;

&lt;p&gt;Illustrating this with an architecture, we can see that we will have to add a small computing capability to our devices (think for example cameras, cars, …) that will then hook up to an event pipeline or IoT Device manager. On top of this we can then add our full lifecycle that can train our model and send the trained model back to the edge devices, creating a perfect loop and self-iterating process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/iot-edge/architecture2.png&quot; alt=&quot;/assets/images/posts/iot-edge/architecture2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So let’s try to simulate this in our own environment! Now since this post would get too big due to the different steps being required, I decided to split it up into different modules:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/iot-edge-part1&quot;&gt;Part 1 - Manage, Connect and Deploy our simulators to our Edge Devices with IoT Hub&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/iot-edge-part2&quot;&gt;Part 2 - Create and Deploy our Machine Learning filters on Edge&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xavier Geerinck</name></author><category term="azure" /><category term="coding-javascript" /><summary type="html">The Internet-Of-Things (IoT) is currently in full roll-out around the world and will only grow with the deployment of 5G, enabling new use cases and collecting more data than ever seen before. An important aspect of this is not only managing the data that you collect, but also correctly filtering and reducing the latency that you experience on-premise. It is not accepted that it takes 10 seconds round-trip from a container ship in the middle of the atlantic ocean, if you need a response for every image of a camera feed at 24fps. A way to solve this is by utilizing edge deployments. Edge deployments allow you to create your model in a scalable environment (cloud) and deploy these to the edge devices. Which can then utilize this model, filter the needed data and send just this data back when the connection is re-established. Interesting use cases for example are: Image processing from live video feeds (drones, street cameras, train tracks, …) Just think about streaming at 24fps, including your model inference and including the network round-trip Dongles in cars, sending the captured data from its CAN-bus If a car sends at 1Hz, what is your captured data rate? It’s predicted that self-driving cars will consume about 4Tb every 1.5 hours! So how can we solve this technical wise? Well you’d be happy to know that currently we have all the tools in place to actually accomplish this on-edge computing already! Illustrating this with an architecture, we can see that we will have to add a small computing capability to our devices (think for example cameras, cars, …) that will then hook up to an event pipeline or IoT Device manager. On top of this we can then add our full lifecycle that can train our model and send the trained model back to the edge devices, creating a perfect loop and self-iterating process. So let’s try to simulate this in our own environment! Now since this post would get too big due to the different steps being required, I decided to split it up into different modules: Part 1 - Manage, Connect and Deploy our simulators to our Edge Devices with IoT Hub Part 2 - Create and Deploy our Machine Learning filters on Edge</summary></entry><entry><title type="html">Automatically create an AI model for your dataset using Azure AutoML</title><link href="/automl-interface-telco-churn-prediction" rel="alternate" type="text/html" title="Automatically create an AI model for your dataset using Azure AutoML" /><published>2019-05-15T09:00:00+00:00</published><updated>2019-05-15T09:00:00+00:00</updated><id>/automl-interface-telco-churn-prediction</id><content type="html" xml:base="/automl-interface-telco-churn-prediction">&lt;p&gt;An annoying part in working with classification, regression or other AI algorithms is that you always need to write a lot of code, prepare your data and do other steps before you are able to get results out of it.&lt;/p&gt;

&lt;p&gt;Tools such as Azure ML Studio, … already allow you to drag &amp;amp; drop all your steps together, but it still is quite some work to get the results you want + it does not automatically tune the different hyperparameters nor does it run the different algorithm to identify which one is the best.&lt;/p&gt;

&lt;p&gt;Now AutoML (Automated Machine Learning) released an interface that does all of this for us, while we just have to click a few things together! :D so let’s try this and create a full End-To-End Scenario of creating our model as well as consuming the created model automatically through the AutoML API.&lt;/p&gt;

&lt;h2 id=&quot;use-case-definition&quot;&gt;Use Case Definition&lt;/h2&gt;

&lt;p&gt;Of course before we can get started, we need a use-case. So let’s take one from our big hat:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Summary:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Use Case:&lt;/strong&gt; In the &lt;em&gt;Telecom&lt;/em&gt; industry, predict if a user will churn or not&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dataset:&lt;/strong&gt; &lt;a href=&quot;https://www.kaggle.com/blastchar/telco-customer-churn&quot;&gt;https://www.kaggle.com/blastchar/telco-customer-churn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; Classification (we either churn or we don’t)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;creating-our-azure-automl-experiment&quot;&gt;Creating our Azure AutoML Experiment&lt;/h2&gt;

&lt;p&gt;Now go to the Azure Portal and search after &lt;strong&gt;Machine Learning Workspaces&lt;/strong&gt; and create your workspace. Once you go to this you will see something like this when you go to “Automated Machine Learning”:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/dashboard.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/dashboard.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So create an experiment:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/create-experiment.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/create-experiment.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And upload your dataset and select it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/create-experiment-2.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/create-experiment-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Whereafter you will see a quick overview of what the data is as well as what we want to do with it (classification).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/create-experiment-3.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/create-experiment-3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Whereafter we can see how it is running and what the results are from the different tunings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-details-prep.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-details-prep.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once the run is completed, we will see the different algorithms that were tested as well as their parameters. With the best performing one on the top.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-completed.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-completed.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When we now click the best performing model, we will be able to download our model:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-completed-2.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-completed-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So let’s download this model. This downloads us a &lt;code class=&quot;highlighter-rouge&quot;&gt;.pkl&lt;/code&gt; file which is a python &lt;a href=&quot;https://docs.python.org/3/library/pickle.html&quot;&gt;pickle&lt;/a&gt; file.&lt;/p&gt;

&lt;h2 id=&quot;downloading-our-model&quot;&gt;Downloading our model&lt;/h2&gt;

&lt;p&gt;Of course if we want to run in Production and completely automated, it doesn’t make sense to manually download our &lt;code class=&quot;highlighter-rouge&quot;&gt;.pkl&lt;/code&gt; file. That is why it is interesting to write a scrip that will do all of that automatically for us. This is what the following code does:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#temp
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.externals&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;joblib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml.core&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Workspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Experiment&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml.core.model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml.train.automl&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tenant_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_tenant_id&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;service_principal_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_service_principal_id&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;service_principal_password&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_service_principal_pw&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;subscription_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_subscription_id&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;resource_group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_resource_group_name&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;workspace_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_ml_services_workspace_name&amp;gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;experiment_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;your_ml_services_experiment_name&amp;gt;&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Print SDK Version
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Azure ML SDK Version: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;azureml&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VERSION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Set up our connection to our workspace
# Note: normally this is in an environment variable or configuration file!
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml.core.authentication&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ServicePrincipalAuthentication&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myServicePrincipal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ServicePrincipalAuthentication&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tenant_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tenant_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service_principal_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service_principal_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service_principal_password&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service_principal_password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ws&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Workspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subscription_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subscription_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resource_group&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resource_group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workspace_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workspace_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myServicePrincipal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;experiment&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ws&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experiment_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;run_latest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experiment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# get_runs returns generator, natural way in python is to use list(&amp;lt;generator&amp;gt;) and working with that
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Print details about the run
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;children&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_latest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;metricslist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;metricslist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'iteration'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;rundata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metricslist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rundata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;best_algorithm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_latest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Best Algorithm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_algorithm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_algorithm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_file_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#print(run_latest.get_children())
# Register the model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_algorithm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;register_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test_model&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'outputs/model.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Download the model 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getcwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exist_ok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getcwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'model.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Model Downloaded as 'model.pkl'&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;consuming-our-model&quot;&gt;Consuming our model&lt;/h2&gt;

&lt;p&gt;As a last step, we are now able to consume our model. For testing purposes, I will do this manually, but for production this should be done through for example a library creation or an API endpoint.&lt;/p&gt;

&lt;p&gt;The way we can consume this model is by creating a dataframe containing our columns (the ones we included in the training earlier) and adding the data to that.&lt;/p&gt;

&lt;p&gt;After that we can then call &lt;code class=&quot;highlighter-rouge&quot;&gt;model.predict(df)&lt;/code&gt; which will utilize this dataframe, send it to our &lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt; function and return our result (&lt;code class=&quot;highlighter-rouge&quot;&gt;yes&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;no&lt;/code&gt; in our case).&lt;/p&gt;

&lt;p&gt;This is how you can do that in python:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml.train.automl&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# pip3 install azureml-sdk[automl,notebooks]
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Azure ML SDK Version: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;azureml&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VERSION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;best_run&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;gender&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;SeniorCitizen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Partner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Dependents&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tenure&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PhoneService&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;MultipleLines&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;InternetService&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;OnlineSecurity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;OnlineBackup&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DeviceProtection&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TechSupport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;StreamingTV&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;StreamingMovies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Contract&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PaperlessBilling&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PaymentMethod&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;MonthlyCharges&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TotalCharges&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Churn = Yes
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Female&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Fiber optic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Month-to-month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Electronic check&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;99.65&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;820.5&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Churn = No
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Male&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;59&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No internet service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No internet service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No internet service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No internet service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No internet service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No internet service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Two year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Credit card (automatic)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;19.3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1192.7&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Churn = Yes
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Male&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;58&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No phone service&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DSL&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Month-to-month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Electronic check&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;45.3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2651.2&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Predict
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Predicting Dataset #1, expect 'Yes', got: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Predicting Dataset #1, expect 'No', got: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Predicting Dataset #1, expect 'Yes', got: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;accuracy-measuring&quot;&gt;Accuracy Measuring&lt;/h2&gt;

&lt;p&gt;A last thing to do is to check our accuracy. You can do this through the portal for the best model, showing the Accuracy or by manually going through the dataset and checking the false positive relative to the line count.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-accuracy.png&quot; alt=&quot;/assets/images/posts/automl-telco-churn-prediction/experiment-accuracy.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of course since we are data scientists, we want to make sure the portal gives the correct result ;) so let’s test this as well through code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;csv&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;azureml.train.automl&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# pip3 install azureml-sdk[automl,notebooks]
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;gender&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;SeniorCitizen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Partner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Dependents&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tenure&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PhoneService&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;MultipleLines&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;InternetService&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;OnlineSecurity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;OnlineBackup&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DeviceProtection&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TechSupport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;StreamingTV&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;StreamingMovies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Contract&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PaperlessBilling&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;PaymentMethod&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;MonthlyCharges&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TotalCharges&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;line_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;false_positive_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;best_run&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csvfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DictReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csvfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gender'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SeniorCitizen'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Partner'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Dependents'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tenure'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'PhoneService'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'MultipleLines'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'InternetService'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'OnlineSecurity'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'OnlineBackup'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'DeviceProtection'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'TechSupport'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'StreamingTV'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'StreamingMovies'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Contract'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'PaperlessBilling'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'PaymentMethod'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'MonthlyCharges'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'TotalCharges'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;line_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Churn'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;false_positive_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Total Samples: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;False Positives: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;false_positive_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accuracy:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;false_positive_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which should give us the same results.&lt;/p&gt;</content><author><name>Xavier Geerinck</name></author><category term="azure" /><category term="coding-python" /><summary type="html">An annoying part in working with classification, regression or other AI algorithms is that you always need to write a lot of code, prepare your data and do other steps before you are able to get results out of it. Tools such as Azure ML Studio, … already allow you to drag &amp;amp; drop all your steps together, but it still is quite some work to get the results you want + it does not automatically tune the different hyperparameters nor does it run the different algorithm to identify which one is the best. Now AutoML (Automated Machine Learning) released an interface that does all of this for us, while we just have to click a few things together! :D so let’s try this and create a full End-To-End Scenario of creating our model as well as consuming the created model automatically through the AutoML API. Use Case Definition Of course before we can get started, we need a use-case. So let’s take one from our big hat: Summary: Use Case: In the Telecom industry, predict if a user will churn or not Dataset: https://www.kaggle.com/blastchar/telco-customer-churn Type: Classification (we either churn or we don’t) Creating our Azure AutoML Experiment Now go to the Azure Portal and search after Machine Learning Workspaces and create your workspace. Once you go to this you will see something like this when you go to “Automated Machine Learning”: So create an experiment: And upload your dataset and select it. Whereafter you will see a quick overview of what the data is as well as what we want to do with it (classification). Whereafter we can see how it is running and what the results are from the different tunings: Once the run is completed, we will see the different algorithms that were tested as well as their parameters. With the best performing one on the top. When we now click the best performing model, we will be able to download our model: So let’s download this model. This downloads us a .pkl file which is a python pickle file. Downloading our model Of course if we want to run in Production and completely automated, it doesn’t make sense to manually download our .pkl file. That is why it is interesting to write a scrip that will do all of that automatically for us. This is what the following code does: import numpy as np import azureml import pandas as pd #temp import os import pickle from sklearn.externals import joblib from azureml.core import Workspace, Run, Experiment from azureml.core.model import Model import azureml.train.automl tenant_id = &quot;&amp;lt;your_tenant_id&amp;gt;&quot; service_principal_id = &quot;&amp;lt;your_service_principal_id&amp;gt;&quot; service_principal_password = &quot;&amp;lt;your_service_principal_pw&amp;gt;&quot; subscription_id = &quot;&amp;lt;your_subscription_id&amp;gt;&quot; resource_group = &quot;&amp;lt;your_resource_group_name&amp;gt;&quot; workspace_name = &quot;&amp;lt;your_ml_services_workspace_name&amp;gt;&quot; experiment_name = &quot;&amp;lt;your_ml_services_experiment_name&amp;gt;&quot; # Print SDK Version print(&quot;Azure ML SDK Version: &quot;, azureml.core.VERSION) # Set up our connection to our workspace # Note: normally this is in an environment variable or configuration file! from azureml.core.authentication import ServicePrincipalAuthentication myServicePrincipal = ServicePrincipalAuthentication(tenant_id=tenant_id, service_principal_id=service_principal_id, service_principal_password=service_principal_password) ws = Workspace(subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name, auth=myServicePrincipal) experiment = Experiment(ws, name=experiment_name) run_latest = list(experiment.get_runs())[0] # get_runs returns generator, natural way in python is to use list(&amp;lt;generator&amp;gt;) and working with that # Print details about the run children = list(run_latest.get_children()) metricslist = {} for run in children: properties = run.get_properties() metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)} metricslist[int(properties['iteration'])] = metrics rundata = pd.DataFrame(metricslist).sort_index(1) print(rundata) best_algorithm = list(run_latest.get_children())[0] print(&quot;Best Algorithm&quot;, best_algorithm) print(best_algorithm.get_file_names()) #print(run_latest.get_children()) # Register the model model = best_algorithm.register_model(model_name=&quot;test_model&quot;, model_path='outputs/model.pkl') print(model.name, model.id, model.version, sep = '\t') # Download the model model.download(target_dir=os.getcwd(), exist_ok=True) file_path = os.path.join(os.getcwd(), 'model.pkl') print(&quot;Model Downloaded as 'model.pkl'&quot;) Consuming our model As a last step, we are now able to consume our model. For testing purposes, I will do this manually, but for production this should be done through for example a library creation or an API endpoint. The way we can consume this model is by creating a dataframe containing our columns (the ones we included in the training earlier) and adding the data to that. After that we can then call model.predict(df) which will utilize this dataframe, send it to our predict function and return our result (yes or no in our case). This is how you can do that in python: import pickle import azureml.train.automl # pip3 install azureml-sdk[automl,notebooks] import pandas as pd print(&quot;Azure ML SDK Version: &quot;, azureml.core.VERSION) with open('model.pkl', 'rb') as fd: best_run = pickle.load(fd) columns = [ &quot;gender&quot;, &quot;SeniorCitizen&quot;, &quot;Partner&quot;, &quot;Dependents&quot;, &quot;tenure&quot;, &quot;PhoneService&quot;, &quot;MultipleLines&quot;, &quot;InternetService&quot;, &quot;OnlineSecurity&quot;, &quot;OnlineBackup&quot;, &quot;DeviceProtection&quot;, &quot;TechSupport&quot;, &quot;StreamingTV&quot;, &quot;StreamingMovies&quot;, &quot;Contract&quot;, &quot;PaperlessBilling&quot;, &quot;PaymentMethod&quot;, &quot;MonthlyCharges&quot;, &quot;TotalCharges&quot; ] # Churn = Yes data1 = [[ &quot;Female&quot;, &quot;0&quot;, &quot;No&quot;, &quot;No&quot;, &quot;8&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Fiber optic&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Month-to-month&quot;, &quot;Yes&quot;, &quot;Electronic check&quot;, &quot;99.65&quot;, &quot;820.5&quot; ]] # Churn = No data2 = [[ &quot;Male&quot;, &quot;0&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;59&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No internet service&quot;, &quot;No internet service&quot;, &quot;No internet service&quot;, &quot;No internet service&quot;, &quot;No internet service&quot;, &quot;No internet service&quot;, &quot;Two year&quot;, &quot;No&quot;, &quot;Credit card (automatic)&quot;, &quot;19.3&quot;, &quot;1192.7&quot; ]] # Churn = Yes data3 = [[ &quot;Male&quot;, &quot;1&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;58&quot;, &quot;No&quot;, &quot;No phone service&quot;, &quot;DSL&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Month-to-month&quot;, &quot;Yes&quot;, &quot;Electronic check&quot;, &quot;45.3&quot;, &quot;2651.2&quot; ]] # Predict df1 = pd.DataFrame(data=data1, columns=columns) df2 = pd.DataFrame(data=data2, columns=columns) df3 = pd.DataFrame(data=data3, columns=columns) print(&quot;Predicting Dataset #1, expect 'Yes', got: &quot;, best_run.predict(df1)) print(&quot;Predicting Dataset #1, expect 'No', got: &quot;, best_run.predict(df2)) print(&quot;Predicting Dataset #1, expect 'Yes', got: &quot;, best_run.predict(df3)) Accuracy Measuring A last thing to do is to check our accuracy. You can do this through the portal for the best model, showing the Accuracy or by manually going through the dataset and checking the false positive relative to the line count. Of course since we are data scientists, we want to make sure the portal gives the correct result ;) so let’s test this as well through code: import csv import pickle import azureml.train.automl # pip3 install azureml-sdk[automl,notebooks] import pandas as pd import numpy as np columns = [ &quot;gender&quot;, &quot;SeniorCitizen&quot;, &quot;Partner&quot;, &quot;Dependents&quot;, &quot;tenure&quot;, &quot;PhoneService&quot;, &quot;MultipleLines&quot;, &quot;InternetService&quot;, &quot;OnlineSecurity&quot;, &quot;OnlineBackup&quot;, &quot;DeviceProtection&quot;, &quot;TechSupport&quot;, &quot;StreamingTV&quot;, &quot;StreamingMovies&quot;, &quot;Contract&quot;, &quot;PaperlessBilling&quot;, &quot;PaymentMethod&quot;, &quot;MonthlyCharges&quot;, &quot;TotalCharges&quot; ] line_count = 0 false_positive_count = 0 with open('model.pkl', 'rb') as fd: best_run = pickle.load(fd) with open('test.csv') as csvfile: reader = csv.DictReader(csvfile) for row in reader: df = pd.DataFrame(data=[[ row['gender'], row['SeniorCitizen'], row['Partner'], row['Dependents'], row['tenure'], row['PhoneService'], row['MultipleLines'], row['InternetService'], row['OnlineSecurity'], row['OnlineBackup'], row['DeviceProtection'], row['TechSupport'], row['StreamingTV'], row['StreamingMovies'], row['Contract'], row['PaperlessBilling'], row['PaymentMethod'], row['MonthlyCharges'], row['TotalCharges'] ]], columns=columns) result = best_run.predict(df)[0] line_count += 1 if (result != row['Churn']): false_positive_count += 1 print(line_count) print(&quot;Total Samples: &quot;, line_count) print(&quot;False Positives: &quot;, false_positive_count) print(&quot;Accuracy:&quot;, (1 - false_positive_count / line_count) * 100, &quot;%&quot;) Which should give us the same results.</summary></entry><entry><title type="html">Sampling a real-time stream</title><link href="/stream-sampling" rel="alternate" type="text/html" title="Sampling a real-time stream" /><published>2019-04-23T09:00:00+00:00</published><updated>2019-04-23T09:00:00+00:00</updated><id>/stream-sampling</id><content type="html" xml:base="/stream-sampling">&lt;p&gt;A common problem when working with real-time streams is that you are unaware of the data going in there due to the vast amount of systems connected to it and producing data. Therefor it is interesting to be able to “sample” a stream, where you will connect to the stream with your credentials, wait till an event comes in and then end the connection.&lt;/p&gt;

&lt;p&gt;But how can we do this easily? What code can make enable us to do this? Well there are some parts that we need to keep in mind when designing:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Streams can be byfrom different producers (Azure Event Hub, Apache Kafka, Socket Stream, …)&lt;/li&gt;
  &lt;li&gt;Streams can receive events in a very large time span (&amp;gt; 10min)&lt;/li&gt;
  &lt;li&gt;Streams can be very fast (millions of events per second)&lt;/li&gt;
  &lt;li&gt;Streams can have events arriving out of order&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the scope for our little project are numbers 1, 2 and 3. So let’s discuss on how we can tackle those and how it resolves into creating our sampler.&lt;/p&gt;

&lt;h2 id=&quot;1-streams-can-be-from-different-producers&quot;&gt;1. Streams can be from different producers&lt;/h2&gt;

&lt;p&gt;Every producer has their own SDK. But how can we make a sampler that supports more than just one? Well it’s all about interfaces! (or actually more commonly called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Strategy_pattern&quot;&gt;&lt;strong&gt;Strategy Pattern&lt;/strong&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We will create 2 methods (&lt;code class=&quot;highlighter-rouge&quot;&gt;open()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;close()&lt;/code&gt;) that our strategies have to implement, so that our parent class can call these methods, without worrying if the underlying class has them or not.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/thebillkidy/PublicProjects/blob/master/JS/Azure/EventHub/StreamSample/stream/IStream.ts&quot;&gt;IStream.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IStream&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;EventEmitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this way, we can relatively easily implement providers for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/thebillkidy/PublicProjects/blob/master/JS/Azure/EventHub/StreamSample/stream/streamEventHub.ts&quot;&gt;Azure Event Hub&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/thebillkidy/PublicProjects/blob/master/JS/Azure/EventHub/StreamSample/stream/streamSocket.ts&quot;&gt;Socket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-streams-can-have-a-large-time-span-between-events&quot;&gt;2. Streams can have a large time span between events&lt;/h2&gt;

&lt;p&gt;Since streams don’t always send events every X seconds, we need to make sure that when designing a sampler, that we take this into account. Therefor we need to create a kind of “timeout” mechanism, that kills the stream if nothing is received within the following seconds.&lt;/p&gt;

&lt;p&gt;In Javascript we can relatively easily do this by utilizing the &lt;code class=&quot;highlighter-rouge&quot;&gt;setTimeout&lt;/code&gt; function that will call a function once it is done&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 1 second&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;timeoutFunction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;setTimeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'triggered'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-streams-can-have-events-arriving-very-fast&quot;&gt;3. Streams can have events arriving very fast&lt;/h2&gt;

&lt;p&gt;Streams are supposed to be fast by nature, so how do we only get one event? Well most of the providers allow you to process incoming messages. But to instantly stop when something arrived, we are best off to use an &lt;code class=&quot;highlighter-rouge&quot;&gt;EventEmitter&lt;/code&gt; that will fire as soon as something arrives.&lt;/p&gt;

&lt;p&gt;This way our main process can catch this event and call our &lt;code class=&quot;highlighter-rouge&quot;&gt;close()&lt;/code&gt; method from point 1.&lt;/p&gt;

&lt;p&gt;For our Socket Stream this looks like this (with &lt;code class=&quot;highlighter-rouge&quot;&gt;onData()&lt;/code&gt; doing just this):&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;eventEmitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;eventEmitter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;eventEmitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;reject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'[StreamSocket] Stream Opened'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;onData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;eventEmitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;emit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'stream_message_received'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-merging-2-promises-with-only-one-firing&quot;&gt;4. Merging 2 promises with only one firing&lt;/h2&gt;

&lt;p&gt;Now the most difficult part comes: “How do we cancel another promise if the other one fired?”&lt;/p&gt;

&lt;p&gt;To solve this, I utilized the &lt;code class=&quot;highlighter-rouge&quot;&gt;EventEmitter&lt;/code&gt; as a kind of &lt;code class=&quot;highlighter-rouge&quot;&gt;bus&lt;/code&gt; concept. The different promises (timeout or event received) will then fire an event through this &lt;code class=&quot;highlighter-rouge&quot;&gt;EventEmitter&lt;/code&gt;, so that &lt;code class=&quot;highlighter-rouge&quot;&gt;once()&lt;/code&gt; an event is received, it will return a main promise.&lt;/p&gt;

&lt;p&gt;Illustrating this:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;EventEmitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;reject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;once&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'event_1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'event1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;once&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'event_2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'event2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Fire event 1 or 2&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;setTimeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;emit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'event_1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;setTimeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;emit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'event_2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h2&gt;

&lt;p&gt;By merging the concepts above, we can now write a sampler that will connect to our different streams and wait till OR a message arrived OR a timeout was received, whereafter it will return us the result through an API that can be written.&lt;/p&gt;

&lt;p&gt;To see this in working code, feel free to check this repository: &lt;a href=&quot;https://github.com/thebillkidy/PublicProjects/tree/master/JS/Azure/EventHub/StreamSample&quot;&gt;https://github.com/thebillkidy/PublicProjects/tree/master/JS/Azure/EventHub/StreamSample&lt;/a&gt;&lt;/p&gt;</content><author><name>Xavier Geerinck</name></author><category term="coding" /><category term="coding-javascript" /><category term="big-data" /><summary type="html">A common problem when working with real-time streams is that you are unaware of the data going in there due to the vast amount of systems connected to it and producing data. Therefor it is interesting to be able to “sample” a stream, where you will connect to the stream with your credentials, wait till an event comes in and then end the connection. But how can we do this easily? What code can make enable us to do this? Well there are some parts that we need to keep in mind when designing: Streams can be byfrom different producers (Azure Event Hub, Apache Kafka, Socket Stream, …) Streams can receive events in a very large time span (&amp;gt; 10min) Streams can be very fast (millions of events per second) Streams can have events arriving out of order … In the scope for our little project are numbers 1, 2 and 3. So let’s discuss on how we can tackle those and how it resolves into creating our sampler. 1. Streams can be from different producers Every producer has their own SDK. But how can we make a sampler that supports more than just one? Well it’s all about interfaces! (or actually more commonly called the Strategy Pattern). We will create 2 methods (open() and close()) that our strategies have to implement, so that our parent class can call these methods, without worrying if the underlying class has them or not. IStream.ts export default interface IStream { open(e: EventEmitter) : void; close() : void; } In this way, we can relatively easily implement providers for: Azure Event Hub Socket 2. Streams can have a large time span between events Since streams don’t always send events every X seconds, we need to make sure that when designing a sampler, that we take this into account. Therefor we need to create a kind of “timeout” mechanism, that kills the stream if nothing is received within the following seconds. In Javascript we can relatively easily do this by utilizing the setTimeout function that will call a function once it is done const timeout = 1000; // 1 second let timeoutFunction = setTimeout(() =&amp;gt; console.log('triggered'), timeout); 3. Streams can have events arriving very fast Streams are supposed to be fast by nature, so how do we only get one event? Well most of the providers allow you to process incoming messages. But to instantly stop when something arrived, we are best off to use an EventEmitter that will fire as soon as something arrives. This way our main process can catch this event and call our close() method from point 1. For our Socket Stream this looks like this (with onData() doing just this): async open(eventEmitter) { this.eventEmitter = eventEmitter; return new Promise((resolve, reject) =&amp;gt; { this.connection = net.connect(this.port, this.host, () =&amp;gt; { return resolve(); }); this.connection.on('data', this.onData.bind(this)); console.log('[StreamSocket] Stream Opened'); }); } onData(msg) { this.eventEmitter.emit('stream_message_received', msg); } 4. Merging 2 promises with only one firing Now the most difficult part comes: “How do we cancel another promise if the other one fired?” To solve this, I utilized the EventEmitter as a kind of bus concept. The different promises (timeout or event received) will then fire an event through this EventEmitter, so that once() an event is received, it will return a main promise. Illustrating this: let bus = new EventEmitter(); let result = await new Promise(async (resolve, reject) =&amp;gt; { bus.once('event_1', (message) =&amp;gt; resolve('event1')); bus.once('event_2', () =&amp;gt; resolve('event2')); // Fire event 1 or 2 setTimeout(() =&amp;gt; bus.emit('event_1'), Math.random() * 4000); setTimeout(() =&amp;gt; bus.emit('event_2'), Math.random() * 4000); }); console.log(result); 5. Conclusion By merging the concepts above, we can now write a sampler that will connect to our different streams and wait till OR a message arrived OR a timeout was received, whereafter it will return us the result through an API that can be written. To see this in working code, feel free to check this repository: https://github.com/thebillkidy/PublicProjects/tree/master/JS/Azure/EventHub/StreamSample</summary></entry><entry><title type="html">Creating an Azure Data Lake Gen 2 File Browser for the Web</title><link href="/azure-data-lake-gen-2-browser" rel="alternate" type="text/html" title="Creating an Azure Data Lake Gen 2 File Browser for the Web" /><published>2019-04-18T09:00:00+00:00</published><updated>2019-04-18T09:00:00+00:00</updated><id>/azure-data-lake-gen-2-browser</id><content type="html" xml:base="/azure-data-lake-gen-2-browser">&lt;p&gt;While working with Azure Data Lake Gen 2 (ADLS Gen 2), I saw that one common ask from the people around me is to be able to interact with it through a web portal. As Microsoft we offer customers the chance already to utilize a tool called &lt;a href=&quot;https://azure.microsoft.com/en-us/features/storage-explorer/&quot;&gt;“Azure Storage Explorer”&lt;/a&gt; but this is a tool that is only available for on-premise systems. What I want to show here is how to create a web portal that can be used for the following use cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Enable your customers to drop files / folders through a web portal with credentials provided by you&lt;/li&gt;
  &lt;li&gt;Manage your Data Lake through an online web portal&lt;/li&gt;
  &lt;li&gt;Allow your employees to manage the Data Lake without requiring a tool to be installed (not all employees can install applications on their PCs)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Preview:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/adls-gen2/browser/files_folders.png&quot; alt=&quot;/assets/images/posts/adls-gen2/browser/files_folders.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let’s go through the main points that you need to implement to be able to replicate this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Azure Authentication&lt;/li&gt;
  &lt;li&gt;Azure Data Lake Gen 2 API&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In case you are interested in the full source code, feel free to grab it at: &lt;a href=&quot;https://github.com/thebillkidy/PublicProjects/tree/master/JS/Azure/Storage/ADLS2/Browser&quot;&gt;https://github.com/thebillkidy/PublicProjects/tree/master/JS/Azure/Storage/ADLS2/Browser&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;1-azure-authentication&quot;&gt;1. Azure Authentication&lt;/h2&gt;

&lt;p&gt;When authenticating a user we want to keep a few things in mind when it comes to allowing them to access files/folders on our company-wide data lake:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lock them to a certain directory&lt;/li&gt;
  &lt;li&gt;Allow them to only see files/folders they have access to&lt;/li&gt;
  &lt;li&gt;Secure our application in such a way that no credential leak is possible&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To solve this, we can utilize something that is called an &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-implicit-grant-flow&quot;&gt;“Implicit Grant Flow”&lt;/a&gt; that is utilized in frontend applications without a backend and allows us to call Azure APIs once authenticated through the token returned.&lt;/p&gt;

&lt;p&gt;Implementing this in a React.js Application is a bit harder when you utilize server side rendering, but when purely using it as a SPA application we are able to utilize the &lt;a href=&quot;https://github.com/facebook/create-react-app&quot;&gt;create-react-app&lt;/a&gt; command and install &lt;a href=&quot;https://www.npmjs.com/package/react-adal&quot;&gt;react-adal&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Our index.js will then utilize react-adal in this way which allows us to now load our react app and be signed in instantly.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;React&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'react'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ReactDOM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'react-dom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;runWithAdal&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'react-adal'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;App&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'./App'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DO_NOT_LOGIN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;runWithAdal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;authContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;ReactDOM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;App&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getElementById&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'root'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DO_NOT_LOGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can now use the &lt;code class=&quot;highlighter-rouge&quot;&gt;Bearer&lt;/code&gt; token provided to authenticate against our API.&lt;/p&gt;

&lt;h2 id=&quot;2-azure-data-lake-gen-2-api&quot;&gt;2. Azure Data Lake Gen 2 API&lt;/h2&gt;

&lt;h3 id=&quot;21-general-api-call&quot;&gt;2.1. General API Call&lt;/h3&gt;

&lt;p&gt;To implement access to our Data Lake, we are able to utilize the excellent REST API as documented at  &lt;a href=&quot;https://docs.microsoft.com/en-us/rest/api/storageservices/data-lake-storage-gen2&quot;&gt;https://docs.microsoft.com/en-us/rest/api/storageservices/data-lake-storage-gen2&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For a generic call for example, we can write code that will create a folder by calling the endpoint http://{accountName}.{dnsSuffix}/{filesystem}/{path}?resource=directory with a PUT method. This we can implement by calling the fetch method with the correct parameters.&lt;/p&gt;

&lt;p&gt;By utilizing the &lt;code class=&quot;highlighter-rouge&quot;&gt;adalApiFetch&lt;/code&gt; method provided in the &lt;code class=&quot;highlighter-rouge&quot;&gt;react-adal&lt;/code&gt; config file as described in its installation documents, we can automatically inject the &lt;code class=&quot;highlighter-rouge&quot;&gt;Bearer&lt;/code&gt; token in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Authorization&lt;/code&gt; header.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileSystemFolderCreate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileSystemName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;folderPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;folderName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;folderName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;folderName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;// Create the folder on the ADLS and reload the current path&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// PUT http://{accountName}.{dnsSuffix}/{filesystem}/{path}?resource={resource}&amp;amp;continuation={continuation}&amp;amp;mode={mode}&amp;amp;timeout={timeout}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adalApiFetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`https://&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;storageAccountName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.dfs.core.windows.net`&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileSystemName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;folderPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;folderName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;?resource=directory`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'PUT'&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// StatusCode 201 should be returned - 201 Created&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;201&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;alert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Something happened while creating the folder&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;22-create-file--split-in-chunks&quot;&gt;2.2. Create File &amp;amp; Split in Chunks&lt;/h3&gt;

&lt;p&gt;Things however get more interesting when you want to create a file. Azure Data Lake implements this through 3 different calls:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create File&lt;/li&gt;
  &lt;li&gt;Append Content&lt;/li&gt;
  &lt;li&gt;Flush file to disk&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Which makes it that we will have to implement those 3 calls after each other (which is luckily more easier to do through promises). Another problem that arises though is that we will have to chunk up our files! So that we can upload files with a unlimited size due to the upload limitations in a POST / PUT method. Now due to promises this can all be simplified to the following:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileSystemFileUpload&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileSystemName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cbUploadProgress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;BYTES_PER_CHUNK&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1048576&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 5Mb&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// 1. Create File Placeholder&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adalApiFetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`https://&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;storageAccountName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.dfs.core.windows.net`&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileSystemName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;?resource=file`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'PUT'&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// 2. Append Content&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;chunkCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;BYTES_PER_CHUNK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`Sending &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;chunkCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; chunks`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;BYTES_PER_CHUNK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`Sending &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;chunkBlob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;BYTES_PER_CHUNK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Callback for progress&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;cbUploadProgress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Upload the different chinks&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;chunkBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resAppend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adalApiFetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`https://&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;storageAccountName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.dfs.core.windows.net`&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileSystemName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;?action=append&amp;amp;position=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'PUT'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;s1&quot;&gt;'Content-Type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'application/octet-stream'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s1&quot;&gt;'Content-Length'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;chunkBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s1&quot;&gt;'X-HTTP-Method-Override'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'PATCH'&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Currently send it as a PUT since PATCH is not supported&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;chunkBlob&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// 3. Flush the file&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resFlush&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adalApiFetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`https://&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;storageAccountName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.dfs.core.windows.net`&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileSystemName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;?action=flush&amp;amp;position=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'PUT'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s1&quot;&gt;'Content-Type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'application/octet-stream'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s1&quot;&gt;'X-HTTP-Method-Override'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'PATCH'&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Currently send it as a PUT since PATCH is not supported&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Callback for progress stating that we are done&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;cbUploadProgress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fileBlob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Xavier Geerinck</name></author><category term="azure" /><category term="coding-javascript" /><summary type="html">While working with Azure Data Lake Gen 2 (ADLS Gen 2), I saw that one common ask from the people around me is to be able to interact with it through a web portal. As Microsoft we offer customers the chance already to utilize a tool called “Azure Storage Explorer” but this is a tool that is only available for on-premise systems. What I want to show here is how to create a web portal that can be used for the following use cases: Enable your customers to drop files / folders through a web portal with credentials provided by you Manage your Data Lake through an online web portal Allow your employees to manage the Data Lake without requiring a tool to be installed (not all employees can install applications on their PCs) Preview: Let’s go through the main points that you need to implement to be able to replicate this: Azure Authentication Azure Data Lake Gen 2 API Note: In case you are interested in the full source code, feel free to grab it at: https://github.com/thebillkidy/PublicProjects/tree/master/JS/Azure/Storage/ADLS2/Browser 1. Azure Authentication When authenticating a user we want to keep a few things in mind when it comes to allowing them to access files/folders on our company-wide data lake: Lock them to a certain directory Allow them to only see files/folders they have access to Secure our application in such a way that no credential leak is possible To solve this, we can utilize something that is called an “Implicit Grant Flow” that is utilized in frontend applications without a backend and allows us to call Azure APIs once authenticated through the token returned. Implementing this in a React.js Application is a bit harder when you utilize server side rendering, but when purely using it as a SPA application we are able to utilize the create-react-app command and install react-adal. Our index.js will then utilize react-adal in this way which allows us to now load our react app and be signed in instantly. import React from 'react'; import ReactDOM from 'react-dom'; import { runWithAdal } from 'react-adal'; import App from './App'; const DO_NOT_LOGIN = false; runWithAdal(authContext, () =&amp;gt; { ReactDOM.render(&amp;lt;App /&amp;gt;, document.getElementById('root')); }, DO_NOT_LOGIN); We can now use the Bearer token provided to authenticate against our API. 2. Azure Data Lake Gen 2 API 2.1. General API Call To implement access to our Data Lake, we are able to utilize the excellent REST API as documented at https://docs.microsoft.com/en-us/rest/api/storageservices/data-lake-storage-gen2. For a generic call for example, we can write code that will create a folder by calling the endpoint http://{accountName}.{dnsSuffix}/{filesystem}/{path}?resource=directory with a PUT method. This we can implement by calling the fetch method with the correct parameters. By utilizing the adalApiFetch method provided in the react-adal config file as described in its installation documents, we can automatically inject the Bearer token in the Authorization header. export const fileSystemFolderCreate = async (fileSystemName, folderPath, folderName) =&amp;gt; { if (!folderName || folderName == &quot;&quot;) { return; } // Create the folder on the ADLS and reload the current path // PUT http://{accountName}.{dnsSuffix}/{filesystem}/{path}?resource={resource}&amp;amp;continuation={continuation}&amp;amp;mode={mode}&amp;amp;timeout={timeout} // https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create const res = await adalApiFetch(fetch, '' + `https://${Config.storageAccountName}.dfs.core.windows.net` + `/${fileSystemName}` + `${folderPath}/${folderName}?resource=directory`, { method: 'PUT' } ); // StatusCode 201 should be returned - 201 Created if (res.status != 201) { alert(&quot;Something happened while creating the folder&quot;); return false; } return true; } 2.2. Create File &amp;amp; Split in Chunks Things however get more interesting when you want to create a file. Azure Data Lake implements this through 3 different calls: Create File Append Content Flush file to disk Which makes it that we will have to implement those 3 calls after each other (which is luckily more easier to do through promises). Another problem that arises though is that we will have to chunk up our files! So that we can upload files with a unlimited size due to the upload limitations in a POST / PUT method. Now due to promises this can all be simplified to the following: export const fileSystemFileUpload = async (fileSystemName, filePath, fileName, fileBlob, cbUploadProgress) =&amp;gt; { const BYTES_PER_CHUNK = 1048576 * 1; // 5Mb // 1. Create File Placeholder const res = await adalApiFetch(fetch, '' + `https://${Config.storageAccountName}.dfs.core.windows.net` + `/${fileSystemName}` + `${filePath}/${fileName}?resource=file`, { method: 'PUT' } ); // 2. Append Content let chunkCount = Math.max(Math.ceil(fileBlob.size / BYTES_PER_CHUNK), 1); console.log(`Sending ${chunkCount} chunks`); for (let i = 0; i &amp;lt; fileBlob.size; i += BYTES_PER_CHUNK) { console.log(`Sending ${i}/${fileBlob.size}`); let chunkBlob = fileBlob.slice(i, i + BYTES_PER_CHUNK); // Callback for progress cbUploadProgress(fileBlob.size, i); // Upload the different chinks console.log(chunkBlob.size); const resAppend = await adalApiFetch(fetch, '' + `https://${Config.storageAccountName}.dfs.core.windows.net` + `/${fileSystemName}` + `${filePath}/${fileName}?action=append&amp;amp;position=${i}`, { method: 'PUT', headers: { 'Content-Type': 'application/octet-stream', 'Content-Length': chunkBlob.size, 'X-HTTP-Method-Override': 'PATCH' // Currently send it as a PUT since PATCH is not supported }, body: chunkBlob } ); } // 3. Flush the file const resFlush = await adalApiFetch(fetch, '' + `https://${Config.storageAccountName}.dfs.core.windows.net` + `/${fileSystemName}` + `${filePath}/${fileName}?action=flush&amp;amp;position=${fileBlob.size}`, { method: 'PUT', headers: { 'Content-Type': 'application/octet-stream', 'X-HTTP-Method-Override': 'PATCH' // Currently send it as a PUT since PATCH is not supported } } ); // Callback for progress stating that we are done cbUploadProgress(fileBlob.size, fileBlob.size); }</summary></entry><entry><title type="html">Continuous Integration for Github Pages with Jekyll in the same repository</title><link href="/deploying-gh-pages-with-azure-pipelines" rel="alternate" type="text/html" title="Continuous Integration for Github Pages with Jekyll in the same repository" /><published>2019-01-27T07:00:00+00:00</published><updated>2019-01-27T07:00:00+00:00</updated><id>/deploying-gh-pages-with-azure-pipelines</id><content type="html" xml:base="/deploying-gh-pages-with-azure-pipelines">&lt;p&gt;So far I have been using Travis-CI as my Continuous Integration (CI) system for my build and release process for my Blog. However recently, VSTS got rebranded to Azure Pipelines, and I felt everything got mature enough to finally migrate to Azure Pipelines. To my surprise this turned out to be super easy! Let’s see how it can be done!&lt;/p&gt;

&lt;p&gt;What do we want to achieve? Well we want to achieve a continuous flow of development, where when we develop a piece of code, the following steps are followed (as illustrated below):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;SCM:&lt;/strong&gt; Use our SCM protocol to push our code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PULL CODE:&lt;/strong&gt; Our source control repository, triggers an event&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BUILD:&lt;/strong&gt; This trigger gets detected by our Pipeline process which builds our code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TEST:&lt;/strong&gt; The Build gets tested&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;FAIL/SUCCESS:&lt;/strong&gt; This results in a failure or success&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RELEASE:&lt;/strong&gt; On success we release our code to the world&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/CI/ci-pipeline.png&quot; alt=&quot;/assets/images/posts/CI/ci-pipeline.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;setting-up-our-pipeline&quot;&gt;Setting up our Pipeline&lt;/h2&gt;

&lt;p&gt;Just as in Travis, we are able to generate a &lt;code class=&quot;highlighter-rouge&quot;&gt;YAML&lt;/code&gt; file in our code repository, that will be picked up by &lt;code class=&quot;highlighter-rouge&quot;&gt;Azure Devops&lt;/code&gt;. So get started by creating a &lt;code class=&quot;highlighter-rouge&quot;&gt;azure-pipelines.yml&lt;/code&gt; file in your root folder.&lt;/p&gt;

&lt;p&gt;For our &lt;code class=&quot;highlighter-rouge&quot;&gt;Github Pages&lt;/code&gt; we want to achieve that whenever we push to &lt;code class=&quot;highlighter-rouge&quot;&gt;development&lt;/code&gt; that everything is build and the built source is pushed to &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt;. This is a quite anti-pattern kind of process, seeing that most of the time we would build to an &lt;code class=&quot;highlighter-rouge&quot;&gt;artifact&lt;/code&gt; and release this artifact to the world. For easiness we however want to do this, to keep our set of tools as minimal as possible.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This build is an anti-pattern because of described above!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To achieve this, we can use the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;On push to &lt;code class=&quot;highlighter-rouge&quot;&gt;development&lt;/code&gt; branch, trigger the process&lt;/li&gt;
  &lt;li&gt;Pull our code (&lt;code class=&quot;highlighter-rouge&quot;&gt;git clone&lt;/code&gt;) from the development branch&lt;/li&gt;
  &lt;li&gt;Build our Jekyll site to a destination folder (&lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll build -d &amp;lt;DESTINATION&amp;gt;&lt;/code&gt;). We can see this as our artifact if we zip it!&lt;/li&gt;
  &lt;li&gt;Create a branch based of &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; (important!) which contained our previous build site&lt;/li&gt;
  &lt;li&gt;Clean the master branch from all files and copy over our artifact files&lt;/li&gt;
  &lt;li&gt;Add our changes and commit&lt;/li&gt;
  &lt;li&gt;Push to remote&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In Azure Pipelines this can be achieved through &lt;code class=&quot;highlighter-rouge&quot;&gt;steps&lt;/code&gt; which describes our steps above in a &lt;code class=&quot;highlighter-rouge&quot;&gt;YAML&lt;/code&gt; kind of structure. So let’s get started by creating our different steps.&lt;/p&gt;

&lt;h3 id=&quot;step-1trigger-on-push-to-development-branch&quot;&gt;Step 1:Trigger on-push to Development Branch&lt;/h3&gt;

&lt;p&gt;Describing to trigger on push is just 2 lines of code:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;trigger&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;development&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-2-pull-our-code&quot;&gt;Step 2: Pull our Code&lt;/h3&gt;

&lt;p&gt;Luckily our code pulling is done automatically, due to the integration with GitHub. We however do have to add our credentials again, since they are removed by default. This way we can push! To do this, add the following:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=azdevops&amp;amp;tabs=schema#checkout&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;checkout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;self&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;persistCredentials&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set to 'true' to leave the OAuth token in the Git config after the initial fetch&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-3-build-our-jekyll-website&quot;&gt;Step 3: Build our Jekyll Website&lt;/h3&gt;

&lt;p&gt;Let’s start by writing our steps that we want to execute when we have our code. For this, we need to know that everything we do is described as a &lt;code class=&quot;highlighter-rouge&quot;&gt;task&lt;/code&gt; under &lt;code class=&quot;highlighter-rouge&quot;&gt;steps&lt;/code&gt;. Looking like this:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Doing this now for our Jekyll build, we will configure it to use ruby, install our dependencies and build our Jekyll website!&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;UseRubyVersion@0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# See: https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/tool/use-ruby-version?view=azdevops&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Use&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Ruby&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2.5'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gem&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bundler'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Install&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Bundler'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;install'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Install&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;and&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dependencies'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;jekyll&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-d&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.ArtifactStagingDirectory)'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Static&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Site'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-4---7-push-our-build-website-to-the-master-branch&quot;&gt;Step 4 - 7: Push our build website to the master branch&lt;/h3&gt;

&lt;p&gt;Building our website is the most complex part, for steps 4 - 7 we get:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cd&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.Repository.LocalPath);&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;git&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;checkout&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;master;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;git&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;checkout&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-b&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;azure-pipelines-build'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Create&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Branch&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;based&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Master'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git rm -rf .; git clean -fxd;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;touch .nojekyll;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;touch README.md;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;echo &quot;# My Blog&quot; &amp;gt;&amp;gt; README.md;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Clean&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Branch'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git config --global user.email &quot;xavier.geerinck@gmail.com&quot;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git config --global user.name &quot;Xavier Geerinck&quot;;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Configure&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Git&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;User'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-a&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.ArtifactStagingDirectory)/.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.Repository.LocalPath)'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Copy&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Artifact&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Files&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Cleaned&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Branch'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git add --all;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git commit -m&quot;Pipelines-Bot: Updated site via $(Build.SourceVersion)&quot;;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Create&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;our&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Commit'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git checkout master;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git merge azure-pipelines-build;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git branch -d azure-pipelines-build;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Merge&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;azure-pipelines-build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;into&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;master'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git push origin master;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Push&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;changes&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;remote'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;final-review-of-our-yaml-file&quot;&gt;Final Review of our YAML file&lt;/h3&gt;

&lt;p&gt;If we correctly followed everything described above, we get the following:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;trigger&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;development&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;vmImage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Ubuntu-16.04'&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=azdevops&amp;amp;tabs=schema#checkout&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;checkout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;self&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;persistCredentials&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set to 'true' to leave the OAuth token in the Git config after the initial fetch&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;UseRubyVersion@0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# See: https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/tool/use-ruby-version?view=azdevops&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Use&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Ruby&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2.5'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gem&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bundler'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Install&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Bundler'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;install'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Install&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;and&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dependencies'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;jekyll&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-d&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.ArtifactStagingDirectory)'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Static&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Site'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cd&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.Repository.LocalPath);&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;git&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;checkout&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;master;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;git&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;checkout&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-b&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;azure-pipelines-build'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Create&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Branch&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;based&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Master'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git rm -rf .; git clean -fxd;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;touch .nojekyll;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;touch README.md;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;echo &quot;# My Blog&quot; &amp;gt;&amp;gt; README.md;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Clean&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Branch'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git config --global user.email &quot;xavier.geerinck@gmail.com&quot;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git config --global user.name &quot;Xavier Geerinck&quot;;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Configure&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Git&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;User'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-a&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.ArtifactStagingDirectory)/.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$(Build.Repository.LocalPath)'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Copy&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Artifact&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Files&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Cleaned&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Branch'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git add --all;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git commit -m&quot;Pipelines-Bot: Updated site via $(Build.SourceVersion)&quot;;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Create&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;our&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Commit'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git checkout master;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git merge azure-pipelines-build;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git branch -d azure-pipelines-build;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Merge&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;azure-pipelines-build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;into&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;master'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;cd $(Build.Repository.LocalPath);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;git push origin master;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Push&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;changes&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;remote'&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Note: github_pat should be configured as an environment variable in devops&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#   -&amp;gt; create github pat here: https://github.com/settings/tokens&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#   -&amp;gt; Create environment variable in dev.azure.com under pipelines -&amp;gt; edit (right top) -&amp;gt; variables (right top triple dots) -&amp;gt; called github_pat -&amp;gt; click the lock&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;gh_user=&quot;thebillkidy&quot;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;gh_pass=$(github_pat);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;gh_repo=&quot;thebillkidy.github.io&quot;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;auth_pass=$(echo -n &quot;${gh_user}:$(github_pat)&quot; | base64);&lt;/span&gt;

    &lt;span class=&quot;no&quot;&gt;curl https://api.github.com/repos/${gh_user}/${gh_repo}/pages/builds -I \&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;-X POST \&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;-H &quot;Accept: application/vnd.github.mister-fantastic-preview+json&quot; \&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;-H &quot;Authorization: Basic ${auth_pass}&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;[GitHub]&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Trigger&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Page&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build'&lt;/span&gt;

&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;gh_user=&quot;thebillkidy&quot;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;gh_pass=$(github_pat);&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;gh_repo=&quot;thebillkidy.github.io&quot;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;auth_pass=$(echo -n &quot;${gh_user}:$(github_pat)&quot; | base64);&lt;/span&gt;

    &lt;span class=&quot;no&quot;&gt;curl https://api.github.com/repos/${gh_user}/${gh_repo}/pages/builds/latest -I \&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;-X GET \&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;-H &quot;Accept: application/vnd.github.mister-fantastic-preview+json&quot; \&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;-H &quot;Authorization: Basic $auth_pass&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;displayName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;[GitHub]&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Get&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Page&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Status'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;When comparing my new Azure Devops Pipelines to the old Travis Job, I am able to say that Azure Devops Pipelines allows me to more fine grained configure my tasks as well as deploy, really showing how strong this product is for the enterprise market.&lt;/p&gt;

&lt;p&gt;Another noticable thing is the performance. When deploying with Travis, my builds often took between 2 - 3minutes, while with Azure Devops Pipelines this takes around 1m 40s&lt;/p&gt;</content><author><name>Xavier Geerinck</name></author><category term="infrastructure" /><category term="devops" /><summary type="html">So far I have been using Travis-CI as my Continuous Integration (CI) system for my build and release process for my Blog. However recently, VSTS got rebranded to Azure Pipelines, and I felt everything got mature enough to finally migrate to Azure Pipelines. To my surprise this turned out to be super easy! Let’s see how it can be done! What do we want to achieve? Well we want to achieve a continuous flow of development, where when we develop a piece of code, the following steps are followed (as illustrated below): SCM: Use our SCM protocol to push our code PULL CODE: Our source control repository, triggers an event BUILD: This trigger gets detected by our Pipeline process which builds our code TEST: The Build gets tested FAIL/SUCCESS: This results in a failure or success RELEASE: On success we release our code to the world Setting up our Pipeline Just as in Travis, we are able to generate a YAML file in our code repository, that will be picked up by Azure Devops. So get started by creating a azure-pipelines.yml file in your root folder. For our Github Pages we want to achieve that whenever we push to development that everything is build and the built source is pushed to master. This is a quite anti-pattern kind of process, seeing that most of the time we would build to an artifact and release this artifact to the world. For easiness we however want to do this, to keep our set of tools as minimal as possible. Note: This build is an anti-pattern because of described above! To achieve this, we can use the following steps: On push to development branch, trigger the process Pull our code (git clone) from the development branch Build our Jekyll site to a destination folder (jekyll build -d &amp;lt;DESTINATION&amp;gt;). We can see this as our artifact if we zip it! Create a branch based of master (important!) which contained our previous build site Clean the master branch from all files and copy over our artifact files Add our changes and commit Push to remote In Azure Pipelines this can be achieved through steps which describes our steps above in a YAML kind of structure. So let’s get started by creating our different steps. Step 1:Trigger on-push to Development Branch Describing to trigger on push is just 2 lines of code: trigger: - development Step 2: Pull our Code Luckily our code pulling is done automatically, due to the integration with GitHub. We however do have to add our credentials again, since they are removed by default. This way we can push! To do this, add the following: # https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=azdevops&amp;amp;tabs=schema#checkout - checkout: self persistCredentials: true # set to 'true' to leave the OAuth token in the Git config after the initial fetch Step 3: Build our Jekyll Website Let’s start by writing our steps that we want to execute when we have our code. For this, we need to know that everything we do is described as a task under steps. Looking like this: steps: - task: Doing this now for our Jekyll build, we will configure it to use ruby, install our dependencies and build our Jekyll website! steps: - task: UseRubyVersion@0 # See: https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/tool/use-ruby-version?view=azdevops displayName: 'Use Ruby &amp;gt;= 2.5' - script: 'gem install bundler' displayName: 'Install Bundler' - script: 'bundle install' displayName: 'Install Jekyll and Dependencies' - script: 'bundle exec jekyll build -d $(Build.ArtifactStagingDirectory)' displayName: 'Build Jekyll Static Site' Step 4 - 7: Push our build website to the master branch Building our website is the most complex part, for steps 4 - 7 we get: - script: 'cd $(Build.Repository.LocalPath); git checkout master; git checkout -b azure-pipelines-build' displayName: 'Create Build Branch based on Master' - script: &amp;gt; cd $(Build.Repository.LocalPath); git rm -rf .; git clean -fxd; touch .nojekyll; touch README.md; echo &quot;# My Blog&quot; &amp;gt;&amp;gt; README.md; displayName: 'Clean Build Branch' - script: &amp;gt; git config --global user.email &quot;xavier.geerinck@gmail.com&quot;; git config --global user.name &quot;Xavier Geerinck&quot;; displayName: 'Configure Git User' - script: 'cp -a $(Build.ArtifactStagingDirectory)/. $(Build.Repository.LocalPath)' displayName: 'Copy Artifact Files to Cleaned Build Branch' - script: &amp;gt; cd $(Build.Repository.LocalPath); git add --all; git commit -m&quot;Pipelines-Bot: Updated site via $(Build.SourceVersion)&quot;; displayName: 'Create our Commit' - script: &amp;gt; cd $(Build.Repository.LocalPath); git checkout master; git merge azure-pipelines-build; git branch -d azure-pipelines-build; displayName: 'Merge azure-pipelines-build into master' - script: &amp;gt; cd $(Build.Repository.LocalPath); git push origin master; displayName: 'Push changes to remote' Final Review of our YAML file If we correctly followed everything described above, we get the following: trigger: - development pool: vmImage: 'Ubuntu-16.04' steps: # https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=azdevops&amp;amp;tabs=schema#checkout - checkout: self persistCredentials: true # set to 'true' to leave the OAuth token in the Git config after the initial fetch - task: UseRubyVersion@0 # See: https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/tool/use-ruby-version?view=azdevops displayName: 'Use Ruby &amp;gt;= 2.5' - script: 'gem install bundler' displayName: 'Install Bundler' - script: 'bundle install' displayName: 'Install Jekyll and Dependencies' - script: 'bundle exec jekyll build -d $(Build.ArtifactStagingDirectory)' displayName: 'Build Jekyll Static Site' - script: 'cd $(Build.Repository.LocalPath); git checkout master; git checkout -b azure-pipelines-build' displayName: 'Create Build Branch based on Master' - script: &amp;gt; cd $(Build.Repository.LocalPath); git rm -rf .; git clean -fxd; touch .nojekyll; touch README.md; echo &quot;# My Blog&quot; &amp;gt;&amp;gt; README.md; displayName: 'Clean Build Branch' - script: &amp;gt; git config --global user.email &quot;xavier.geerinck@gmail.com&quot;; git config --global user.name &quot;Xavier Geerinck&quot;; displayName: 'Configure Git User' - script: 'cp -a $(Build.ArtifactStagingDirectory)/. $(Build.Repository.LocalPath)' displayName: 'Copy Artifact Files to Cleaned Build Branch' - script: &amp;gt; cd $(Build.Repository.LocalPath); git add --all; git commit -m&quot;Pipelines-Bot: Updated site via $(Build.SourceVersion)&quot;; displayName: 'Create our Commit' - script: &amp;gt; cd $(Build.Repository.LocalPath); git checkout master; git merge azure-pipelines-build; git branch -d azure-pipelines-build; displayName: 'Merge azure-pipelines-build into master' - script: &amp;gt; cd $(Build.Repository.LocalPath); git push origin master; displayName: 'Push changes to remote' # Note: github_pat should be configured as an environment variable in devops # -&amp;gt; create github pat here: https://github.com/settings/tokens # -&amp;gt; Create environment variable in dev.azure.com under pipelines -&amp;gt; edit (right top) -&amp;gt; variables (right top triple dots) -&amp;gt; called github_pat -&amp;gt; click the lock - script: | gh_user=&quot;thebillkidy&quot;; gh_pass=$(github_pat); gh_repo=&quot;thebillkidy.github.io&quot;; auth_pass=$(echo -n &quot;${gh_user}:$(github_pat)&quot; | base64); curl https://api.github.com/repos/${gh_user}/${gh_repo}/pages/builds -I \ -X POST \ -H &quot;Accept: application/vnd.github.mister-fantastic-preview+json&quot; \ -H &quot;Authorization: Basic ${auth_pass}&quot; displayName: '[GitHub] Trigger Page Build' - script: | gh_user=&quot;thebillkidy&quot;; gh_pass=$(github_pat); gh_repo=&quot;thebillkidy.github.io&quot;; auth_pass=$(echo -n &quot;${gh_user}:$(github_pat)&quot; | base64); curl https://api.github.com/repos/${gh_user}/${gh_repo}/pages/builds/latest -I \ -X GET \ -H &quot;Accept: application/vnd.github.mister-fantastic-preview+json&quot; \ -H &quot;Authorization: Basic $auth_pass&quot; displayName: '[GitHub] Get Page Build Status' Conclusion When comparing my new Azure Devops Pipelines to the old Travis Job, I am able to say that Azure Devops Pipelines allows me to more fine grained configure my tasks as well as deploy, really showing how strong this product is for the enterprise market. Another noticable thing is the performance. When deploying with Travis, my builds often took between 2 - 3minutes, while with Azure Devops Pipelines this takes around 1m 40s</summary></entry><entry><title type="html">Quantum Computing - An Introduction</title><link href="/quantum-an-introduction" rel="alternate" type="text/html" title="Quantum Computing - An Introduction" /><published>2019-01-16T10:00:00+00:00</published><updated>2019-01-16T10:00:00+00:00</updated><id>/quantum-an-introduction</id><content type="html" xml:base="/quantum-an-introduction">&lt;p&gt;Quantum Computing is a hype growing more and more these days, but what is it? Why should we use it and how can we get started with it? This is what I would like to tackle in this post.&lt;/p&gt;

&lt;h2 id=&quot;quantum-computing&quot;&gt;Quantum Computing?&lt;/h2&gt;

&lt;p&gt;As written in the excellent publication by &lt;a href=&quot;/assets/pdf/Richard_P_Feynman-Simulating_Physics_With_Computers.pdf&quot;&gt;Richard P. Feynman - Simulating Physics with Computers&lt;/a&gt;, we would like to have a kind of computer that does exactly the same as nature. A computer that is able to simulate the real world better, and next to that allows us to tackle larger and more complex problems. Think for example about problems such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quantum Chemistry&lt;/li&gt;
  &lt;li&gt;Quantum Dynamics&lt;/li&gt;
  &lt;li&gt;Material Science&lt;/li&gt;
  &lt;li&gt;Optimization Problems&lt;/li&gt;
  &lt;li&gt;Sampling&lt;/li&gt;
  &lt;li&gt;Secure Computing&lt;/li&gt;
  &lt;li&gt;Cryptography&lt;/li&gt;
  &lt;li&gt;Machine Learning&lt;/li&gt;
  &lt;li&gt;Searching&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To solve these kind of problems, we need to fundamentally change computers as they work now, transforming from classical &lt;code class=&quot;highlighter-rouge&quot;&gt;bits&lt;/code&gt; towards &lt;code class=&quot;highlighter-rouge&quot;&gt;qubits&lt;/code&gt;. However before we get started, I recommend you to take a refresher of &lt;a href=&quot;/quantum-linear-algebra&quot;&gt;Linear Algebra&lt;/a&gt; to have the fundamentals needed to continue :)&lt;/p&gt;

&lt;h2 id=&quot;qubits&quot;&gt;Qubits?&lt;/h2&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Now what are Qubits? When we look at nature, it does not represent everything binary as we do now, take a look at these examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An electron can be in spin up or spin down&lt;/li&gt;
  &lt;li&gt;A photon can have a vertical or horizontal polarization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All these kind of examples can be represented as a qubit, representing a 2-state quantum mechanical system.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;How does an electron look with its spins?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/quantum/introduction/spin-quantum-number.png&quot; alt=&quot;/assets/images/posts/quantum/introduction/spin-quantum-number.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are 2 main aspects in Quantum Physics:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Entanglement:&lt;/strong&gt; Particles can become connected so that we can predict the state of the other (e.g. one elctron is spin-up, then we know the other is spin-down if they are entangled)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Superposition:&lt;/strong&gt; A quantum system can be in multiple states at the same time until it is measured&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mathmatical-representation&quot;&gt;Mathmatical Representation&lt;/h3&gt;

&lt;p&gt;Of course to be useful in Quantum Computing, we need to represent these qubits in a mathmatical way. This we can by using the “ket” notation of before, representing a qubit as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vert \psi \rangle = \alpha \vert 0 \rangle + \beta \vert 1 \rangle =
\alpha *
\begin{bmatrix}
1 \\
0
\end{bmatrix}
+ \beta *
\begin{bmatrix}
0 \\
1
\end{bmatrix}&lt;/script&gt;

&lt;p&gt;With $\alpha$ and $\beta$ being probability amplitudes (describes the behaviour of the system), with extra constraint that $\vert \alpha \vert^2 + \vert \beta \vert^2 = 1$&lt;/p&gt;

&lt;p&gt;Seeing that we are working with a 2-level system that uses complex numbers, we can thus represent this on a sphere called the &lt;strong&gt;Bloch Sphere&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/quantum/introduction/bloch-sphere.png&quot; alt=&quot;/assets/images/posts/quantum/introduction/bloch-sphere.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where the angles are described by: $\alpha = cos(\frac{\theta}{2})$ and $\beta = e^{i * \theta} * sin(\frac{\theta}{2})$&lt;/p&gt;

&lt;h2 id=&quot;using-quantum-circuits-to-create-quantum-algorithms&quot;&gt;Using Quantum Circuits to create Quantum Algorithms&lt;/h2&gt;

&lt;h3 id=&quot;introduction-1&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;To start working with Quantum Computing, we create circuits by using quantum gates. A good overview of the different gates can be found on &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantum_logic_gate&quot;&gt;Wikipedia&lt;/a&gt;, so I will not go too much on depth on these. These Quantum Gates are the building blocks of circuits and allow us to write our different programs and algorithms.&lt;/p&gt;

&lt;h3 id=&quot;a-mathmatical-example&quot;&gt;A mathmatical example&lt;/h3&gt;

&lt;p&gt;Let’s actually calculate an example. When we for example combine a hadamard gate with a CNOT gate:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The Hadamard Gate is called the “Fair Coin Flip”, inducing an equal probability of the qubit being in either of the states&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/quantum/introduction/H_CNOTGate.png&quot; alt=&quot;/assets/images/posts/quantum/introduction/H_CNOTGate.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then we know the following:&lt;/p&gt;

&lt;!-- Define Psi, Theta, Hadamard, Identity and CNOT --&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\vert \psi \rangle =
\begin{bmatrix}
\alpha \\
\beta
\end{bmatrix}
;
\vert \theta \rangle =
\begin{bmatrix}
\gamma \\
\delta
\end{bmatrix}
;
H
=
\frac{1}{\sqrt(2)}
*
\begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1
\end{bmatrix}
;
I
=
\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix}
;
CNOT
=
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Which we can work out for 2 cross products already (Psi and Gamma; Hadamard and Identity):&lt;/p&gt;

&lt;!-- Work out Cross Product of Psi and Gamma, Hadamard and Identity --&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\vert \psi \rangle
\otimes
\vert \theta \rangle
=
\begin{bmatrix}
\alpha \gamma \\
\alpha \delta \\
\beta \gamma \\
\beta \delta
\end{bmatrix}
;
H \otimes I
=
\frac{1}{\sqrt(2)}
*
\begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1
\end{bmatrix}
*
\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix}
=
\frac{1}{\sqrt(2)}
*
\begin{bmatrix}
1 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; -1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; -1
\end{bmatrix} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Resulting in:&lt;/p&gt;

&lt;!-- Result --&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
CNOT * (H \otimes I) * (\vert \psi \rangle \otimes \vert \theta \rangle)
=
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}
\frac{1}{\sqrt(2)}
*
\begin{bmatrix}
1 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; -1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; -1
\end{bmatrix}
\begin{bmatrix}
\alpha \gamma \\
\alpha \delta \\
\beta \gamma \\
\beta \delta
\end{bmatrix}
\\
=
\frac{1}{\sqrt(2)}
*
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}
\begin{bmatrix}
\alpha \gamma + \beta \gamma \\
\alpha \delta + \beta \delta \\
\beta \gamma - \beta \gamma \\
\beta \delta - \beta \delta
\end{bmatrix}
=
\frac{1}{\sqrt(2)}
*
\begin{bmatrix}
\alpha \gamma + \beta \gamma \\
\alpha \delta + \beta \delta \\
\alpha \delta - \beta \delta \\
\alpha \gamma - \beta \gamma
\end{bmatrix} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;quantum-algorithms&quot;&gt;Quantum Algorithms&lt;/h3&gt;

&lt;p&gt;Interesting Quantum Algorithms are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Grover Search:&lt;/strong&gt; Find an element in an unordered array. Worse case using Quantum here is $\sqrt(n)$ which is normally N using convential algorithms.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Short’s Factoring:&lt;/strong&gt; Factor an integer in its prime factors. With Quantum this is possible in Polynomial time (RSA encryption is based on Prime Factors, showing the impact quantum can have here)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For an implementation of these algorithms, feel free to check this awesome &lt;a href=&quot;https://people.cs.umass.edu/~strubell/doc/quantum_tutorial.pdf&quot;&gt;article&lt;/a&gt;&lt;/p&gt;</content><author><name>Xavier Geerinck</name></author><category term="quantum" /><summary type="html">Quantum Computing is a hype growing more and more these days, but what is it? Why should we use it and how can we get started with it? This is what I would like to tackle in this post. Quantum Computing? As written in the excellent publication by Richard P. Feynman - Simulating Physics with Computers, we would like to have a kind of computer that does exactly the same as nature. A computer that is able to simulate the real world better, and next to that allows us to tackle larger and more complex problems. Think for example about problems such as: Quantum Chemistry Quantum Dynamics Material Science Optimization Problems Sampling Secure Computing Cryptography Machine Learning Searching To solve these kind of problems, we need to fundamentally change computers as they work now, transforming from classical bits towards qubits. However before we get started, I recommend you to take a refresher of Linear Algebra to have the fundamentals needed to continue :) Qubits? Introduction Now what are Qubits? When we look at nature, it does not represent everything binary as we do now, take a look at these examples: An electron can be in spin up or spin down A photon can have a vertical or horizontal polarization All these kind of examples can be represented as a qubit, representing a 2-state quantum mechanical system. How does an electron look with its spins? There are 2 main aspects in Quantum Physics: Entanglement: Particles can become connected so that we can predict the state of the other (e.g. one elctron is spin-up, then we know the other is spin-down if they are entangled) Superposition: A quantum system can be in multiple states at the same time until it is measured Mathmatical Representation Of course to be useful in Quantum Computing, we need to represent these qubits in a mathmatical way. This we can by using the “ket” notation of before, representing a qubit as: With $\alpha$ and $\beta$ being probability amplitudes (describes the behaviour of the system), with extra constraint that $\vert \alpha \vert^2 + \vert \beta \vert^2 = 1$ Seeing that we are working with a 2-level system that uses complex numbers, we can thus represent this on a sphere called the Bloch Sphere: Where the angles are described by: $\alpha = cos(\frac{\theta}{2})$ and $\beta = e^{i * \theta} * sin(\frac{\theta}{2})$ Using Quantum Circuits to create Quantum Algorithms Introduction To start working with Quantum Computing, we create circuits by using quantum gates. A good overview of the different gates can be found on Wikipedia, so I will not go too much on depth on these. These Quantum Gates are the building blocks of circuits and allow us to write our different programs and algorithms. A mathmatical example Let’s actually calculate an example. When we for example combine a hadamard gate with a CNOT gate: The Hadamard Gate is called the “Fair Coin Flip”, inducing an equal probability of the qubit being in either of the states Then we know the following: Which we can work out for 2 cross products already (Psi and Gamma; Hadamard and Identity): Resulting in: Quantum Algorithms Interesting Quantum Algorithms are: Grover Search: Find an element in an unordered array. Worse case using Quantum here is $\sqrt(n)$ which is normally N using convential algorithms. Short’s Factoring: Factor an integer in its prime factors. With Quantum this is possible in Polynomial time (RSA encryption is based on Prime Factors, showing the impact quantum can have here) For an implementation of these algorithms, feel free to check this awesome article</summary></entry><entry><title type="html">Creating a Big Data cluster with SQL Server 2019</title><link href="/sql-server-2019-big-data-clusters" rel="alternate" type="text/html" title="Creating a Big Data cluster with SQL Server 2019" /><published>2019-01-16T09:00:00+00:00</published><updated>2019-01-16T09:00:00+00:00</updated><id>/sql-server-2019-big-data-clusters</id><content type="html" xml:base="/sql-server-2019-big-data-clusters">&lt;p&gt;SQL Server 2019 came out in preview a while ago, and the new features announced are just wonderful! A one-to-go-tool for all your big data needs: Unstructured and Structured data that can be processed using just one tool!&lt;/p&gt;

&lt;p&gt;But the most wonderful feature of all in my opinion are the “Big Data Clusters”, allowing you to spin up scalable clusters and deploy SQL Server, Spark and HDFS containers side-by-side. But how does it accomplish all of this? Well the architecture below shows us the magic:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/sql-server-2019/architecture.png&quot; alt=&quot;/assets/images/posts/sql-server-2019/architecture.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/sql-server-2019/architecture2.png&quot; alt=&quot;/assets/images/posts/sql-server-2019/architecture2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So what will we do in this post? Well here we will do just that! Deploy our Big Data Cluster and start running our notebooks and SQL queries on it!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: There is documentation available that explains all of this, but I would like to present an easy to understand view for all developers out there. In any case feel free to check this documentation at: &lt;a href=&quot;https://docs.microsoft.com/en-us/sql/big-data-cluster/quickstart-big-data-cluster-deploy?view=sqlallproducts-allversions&quot;&gt;https://docs.microsoft.com/en-us/sql/big-data-cluster/quickstart-big-data-cluster-deploy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Big Note: This is a very large deployment and it’s recommended to have a aks cluster size of &lt;strong&gt;64GB RAM&lt;/strong&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;Before we can get started, it’s required to have &lt;code class=&quot;highlighter-rouge&quot;&gt;mssqlctl&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;azure-cli&lt;/code&gt; installed and have an AKS cluster running.&lt;/p&gt;

&lt;h3 id=&quot;az-cli&quot;&gt;AZ CLI&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Needed on WSL&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; libssl-dev libffi-dev
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; python-dev

&lt;span class=&quot;c&quot;&gt;# Modify Sources&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;apt-transport-https lsb-release software-properties-common &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;AZ_REPO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;lsb_release &lt;span class=&quot;nt&quot;&gt;-cs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$AZ_REPO&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; main&quot;&lt;/span&gt; | &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;sudo tee&lt;/span&gt; /etc/apt/sources.list.d/azure-cli.list

&lt;span class=&quot;c&quot;&gt;# Microsoft Signing Key&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key &lt;span class=&quot;nt&quot;&gt;--keyring&lt;/span&gt; /etc/apt/trusted.gpg.d/Microsoft.gpg adv &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--keyserver&lt;/span&gt; packages.microsoft.com &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--recv-keys&lt;/span&gt; BC528686B50D79E339D3721CEB3E94ADBE1229CF

&lt;span class=&quot;c&quot;&gt;# Install&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;azure-cli
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;mssqlctl&quot;&gt;mssqlctl&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Install Python&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; python3 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; python3-pip &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; pip3 &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--upgrade&lt;/span&gt; pip

&lt;span class=&quot;c&quot;&gt;# Install mssqlctl&lt;/span&gt;
pip3 &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--index-url&lt;/span&gt; https://private-repo.microsoft.com/python/ctp-2.2 mssqlctl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;aks&quot;&gt;AKS&lt;/h3&gt;

&lt;p&gt;Deploy an AKS instance quickly:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We can get the node sizes easily through the command: &lt;code class=&quot;highlighter-rouge&quot;&gt;az vm list-sizes -l  &amp;lt;YOUR_LOCATION&amp;gt; --query &quot;[?numberOfCores&amp;lt;=`16`  &amp;amp;&amp;amp; numberOfCores&amp;gt;=`8`  &amp;amp;&amp;amp; memoryInMb&amp;gt;=`16384`]&quot; -o table&lt;/code&gt; –&amp;gt; see &lt;a href=&quot;http://jmespath.org/examples.html&quot;&gt;http://jmespath.org/examples.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note 2:&lt;/strong&gt; We can get our Kubernetes versions through &lt;code class=&quot;highlighter-rouge&quot;&gt;az aks get-versions -l &amp;lt;YOUR_LOCATION&amp;gt; --query &quot;orchestrators[].orchestratorVersion&quot;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Set our Azure Context&lt;/span&gt;
az account &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &amp;lt;SUBSCRIPTION_ID&amp;gt;

&lt;span class=&quot;c&quot;&gt;# Create our Resource Group (e.g. az group create -n Xavier-SQLBigData -l westeurope)&lt;/span&gt;
az group create &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &amp;lt;YOUR_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; &amp;lt;REGION&amp;gt;

&lt;span class=&quot;c&quot;&gt;# Create AKS in our resource group&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. az aks create --name Xavier-SQLBigDataCluster --resource-group Xavier-SQLBigData --generate-ssh-keys --node-vm-size &quot;Standard_D8_v3&quot; --node-count 3 --kubernetes-version &quot;1.11.5&quot;&lt;/span&gt;
az aks create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; &amp;lt;CLUSTER_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;--resource-group&lt;/span&gt; &amp;lt;YOUR_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;--generate-ssh-keys&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--node-vm-size&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Standard_D8_v3&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--node-count&lt;/span&gt; 3 &lt;span class=&quot;nt&quot;&gt;--kubernetes-version&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;1.11.5&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Get the credentials&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. az aks get-credentials --name Xavier-SQLBigDataCluster --resource-group Xavier-SQLBigData --admin&lt;/span&gt;
az aks get-credentials &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; &amp;lt;CLUSTER_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;--resource-group&lt;/span&gt; &amp;lt;YOUR_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;--admin&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# If needed, view the cluster with&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. az aks browse --name Xavier-SQLBigDataCluster --resource-group Xavier-SQLBigData&lt;/span&gt;
az aks browse &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; &amp;lt;CLUSTER_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;--resource-group&lt;/span&gt; &amp;lt;YOUR_NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;create-our-sql-server-big-data-cluster&quot;&gt;Create our SQL Server Big Data Cluster&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Create SQL Big Data Cluster&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. mssqlctl create cluster sql-server-cluster&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ACCEPT_EULA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Y
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLUSTER_PLATFORM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aks&quot;&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CONTROLLER_USERNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;admin&quot;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# change to what you want&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CONTROLLER_PASSWORD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Test123#&quot;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# change to what you want&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;MSSQL_SA_PASSWORD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Test123#&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KNOX_PASSWORD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Test123#&quot;&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DOCKER_REGISTRY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;private-repo.microsoft.com&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DOCKER_REPOSITORY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mssql-private-preview&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DOCKER_USERNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;docker-email@something.comm&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DOCKER_PASSWORD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;docker-password&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DOCKER_EMAIL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;docker-email@something.com&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DOCKER_PRIVATE_REGISTRY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;

mssqlctl create cluster &amp;lt;CLUSTER_NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let’s start easy by creating our SQL Server Big Data Cluster, this will deploy the complete cluster on the AKS cluster we created earlier. It will look like this:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-01-16 09:30:35.0826 UTC | INFO | Creating cluster...
2019-01-16 09:30:37.0313 UTC | INFO | Deploying controller...
2019-01-16 09:30:39.0764 UTC | INFO | The service account token is ready &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;controller
2019-01-16 09:30:41.0613 UTC | INFO | Waiting &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;controller pod to be up...
... it takes a &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; ...
2019-01-16 09:39:40.0930 UTC | INFO | Waiting &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;controller pod to be up...
2019-01-16 09:39:46.0337 UTC | INFO | Controller pod is running.
2019-01-16 09:39:46.0542 UTC | INFO | Controller Endpoint: https://11.22.33.44:30080
2019-01-16 09:43:15.0898 UTC | INFO | Deployment progress can be tracked at Portal Endpoint: https://11.22.33.44:30777/portal/
2019-01-16 09:43:15.0905 UTC | INFO | Deploying cluster...
2019-01-16 09:43:16.0627 UTC | INFO | Cluster monitoring is ready.
2019-01-16 09:43:16.0627 UTC | INFO | Initiating cluster creation.
2019-01-16 09:43:16.0628 UTC | INFO | Creating cluster with name: sql-server-cluster
2019-01-16 09:56:14.0388 UTC | INFO | Control plane is ready.
2019-01-16 10:02:38.0710 UTC | INFO | Storage pool is ready.
2019-01-16 10:02:38.0711 UTC | INFO | Data pool is ready.
2019-01-16 10:03:06.0027 UTC | INFO | Master pool is ready.
2019-01-16 10:03:23.0044 UTC | INFO | Compute pool is ready.
2019-01-16 10:03:24.0355 UTC | INFO | Cluster state: Ready
2019-01-16 10:03:24.0355 UTC | INFO | Monitor and track your cluster at the Portal Endpoint: https://11.22.33.44:30777/portal/
2019-01-16 10:03:24.0356 UTC | INFO | Cluster deployed successfully.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Allowing you to login on the your cluster!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/sql-server-2019/big-data-cluster-dashboard-overview.png&quot; alt=&quot;/assets/images/posts/sql-server-2019/big-data-cluster-dashboard-overview.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/sql-server-2019/big-data-cluster-dashboard-endpoints.png&quot; alt=&quot;/assets/images/posts/sql-server-2019/big-data-cluster-dashboard-endpoints.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/sql-server-2019/big-data-cluster-dashboard-deployment.png&quot; alt=&quot;/assets/images/posts/sql-server-2019/big-data-cluster-dashboard-deployment.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;display-information-about-our-cluster&quot;&gt;Display Information about our cluster&lt;/h2&gt;

&lt;p&gt;Let’s see how we can get the information to login on our cluster through commands for automation:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Note: view detailed info through `kubectl get service kubernetes -o json`&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Get endpoint-master-pool&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. kubectl get svc endpoint-master-pool -n sql-server-cluster -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot;&lt;/span&gt;
kubectl get service endpoint-master-pool &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &amp;lt;CLUSTER_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;custom-columns&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt; 

&lt;span class=&quot;c&quot;&gt;# Get Service Security Loadbalancer&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. kubectl get svc service-security-lb -n sql-server-cluster -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot;&lt;/span&gt;
kubectl get service service-security-lb &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &amp;lt;CLUSTER_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;custom-columns&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;IP:status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Cluster Admin Portal&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# e.g. kubectl get svc service-proxy-lb -n sql-server-cluster -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot;&lt;/span&gt;
kubectl get service service-proxy-lb &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &amp;lt;CLUSTER_NAME&amp;gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;custom-columns&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;IP:status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can now open our Azure Data Studio and login on our clusters:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SQL: IP and PORT received from &lt;code class=&quot;highlighter-rouge&quot;&gt;endpoint-master-pool&lt;/code&gt; (use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;IP&amp;gt;,&amp;lt;PORT&amp;gt;&lt;/code&gt; format in Data Studio)&lt;/li&gt;
  &lt;li&gt;Spark/HDFS: IP received from &lt;code class=&quot;highlighter-rouge&quot;&gt;service-security-lb&lt;/code&gt; (no port required on connection)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: For Spark/HDFS we use username: &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt;, password: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;your_password&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: For SQL we use username: &lt;code class=&quot;highlighter-rouge&quot;&gt;sa&lt;/code&gt;, password: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;your_sa_password&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- ![/assets/images/posts/sql-server-2019/data-studio-sql.png](/assets/images/posts/sql-server-2019/data-studio-sql.png) --&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/sql-server-2019/data-studio-hdfs-overview.png&quot; alt=&quot;/assets/images/posts/sql-server-2019/data-studio-hdfs-overview.png&quot; /&gt;&lt;/p&gt;</content><author><name>Xavier Geerinck</name></author><category term="big-data" /><category term="infrastructure" /><category term="coding-sql" /><summary type="html">SQL Server 2019 came out in preview a while ago, and the new features announced are just wonderful! A one-to-go-tool for all your big data needs: Unstructured and Structured data that can be processed using just one tool! But the most wonderful feature of all in my opinion are the “Big Data Clusters”, allowing you to spin up scalable clusters and deploy SQL Server, Spark and HDFS containers side-by-side. But how does it accomplish all of this? Well the architecture below shows us the magic: So what will we do in this post? Well here we will do just that! Deploy our Big Data Cluster and start running our notebooks and SQL queries on it! Note: There is documentation available that explains all of this, but I would like to present an easy to understand view for all developers out there. In any case feel free to check this documentation at: https://docs.microsoft.com/en-us/sql/big-data-cluster/quickstart-big-data-cluster-deploy Big Note: This is a very large deployment and it’s recommended to have a aks cluster size of 64GB RAM! Prerequisites Before we can get started, it’s required to have mssqlctl and azure-cli installed and have an AKS cluster running. AZ CLI # Needed on WSL sudo apt-get update sudo apt-get install -y libssl-dev libffi-dev sudo apt-get install -y python-dev # Modify Sources sudo apt-get install apt-transport-https lsb-release software-properties-common -y AZ_REPO=$(lsb_release -cs) echo &quot;deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main&quot; | \ sudo tee /etc/apt/sources.list.d/azure-cli.list # Microsoft Signing Key sudo apt-key --keyring /etc/apt/trusted.gpg.d/Microsoft.gpg adv \ --keyserver packages.microsoft.com \ --recv-keys BC528686B50D79E339D3721CEB3E94ADBE1229CF # Install sudo apt-get update sudo apt-get install azure-cli mssqlctl # Install Python sudo apt-get update &amp;amp;&amp;amp; / sudo apt-get install -y python3 &amp;amp;&amp;amp; / sudo apt-get install -y python3-pip &amp;amp;&amp;amp; / sudo -H pip3 install --upgrade pip # Install mssqlctl pip3 install --index-url https://private-repo.microsoft.com/python/ctp-2.2 mssqlctl AKS Deploy an AKS instance quickly: Note: We can get the node sizes easily through the command: az vm list-sizes -l &amp;lt;YOUR_LOCATION&amp;gt; --query &quot;[?numberOfCores&amp;lt;=`16` &amp;amp;&amp;amp; numberOfCores&amp;gt;=`8` &amp;amp;&amp;amp; memoryInMb&amp;gt;=`16384`]&quot; -o table –&amp;gt; see http://jmespath.org/examples.html Note 2: We can get our Kubernetes versions through az aks get-versions -l &amp;lt;YOUR_LOCATION&amp;gt; --query &quot;orchestrators[].orchestratorVersion&quot; # Set our Azure Context az account set -s &amp;lt;SUBSCRIPTION_ID&amp;gt; # Create our Resource Group (e.g. az group create -n Xavier-SQLBigData -l westeurope) az group create -n &amp;lt;YOUR_NAME&amp;gt; -l &amp;lt;REGION&amp;gt; # Create AKS in our resource group # e.g. az aks create --name Xavier-SQLBigDataCluster --resource-group Xavier-SQLBigData --generate-ssh-keys --node-vm-size &quot;Standard_D8_v3&quot; --node-count 3 --kubernetes-version &quot;1.11.5&quot; az aks create --name &amp;lt;CLUSTER_NAME&amp;gt; --resource-group &amp;lt;YOUR_NAME&amp;gt; --generate-ssh-keys --node-vm-size &quot;Standard_D8_v3&quot; --node-count 3 --kubernetes-version &quot;1.11.5&quot; # Get the credentials # e.g. az aks get-credentials --name Xavier-SQLBigDataCluster --resource-group Xavier-SQLBigData --admin az aks get-credentials --name &amp;lt;CLUSTER_NAME&amp;gt; --resource-group &amp;lt;YOUR_NAME&amp;gt; --admin # If needed, view the cluster with # e.g. az aks browse --name Xavier-SQLBigDataCluster --resource-group Xavier-SQLBigData az aks browse --name &amp;lt;CLUSTER_NAME&amp;gt; --resource-group &amp;lt;YOUR_NAME&amp;gt; Create our SQL Server Big Data Cluster # Create SQL Big Data Cluster # e.g. mssqlctl create cluster sql-server-cluster export ACCEPT_EULA=Y export CLUSTER_PLATFORM=&quot;aks&quot; export CONTROLLER_USERNAME=&quot;admin&quot; # change to what you want export CONTROLLER_PASSWORD=&quot;Test123#&quot; # change to what you want export MSSQL_SA_PASSWORD=&quot;Test123#&quot; export KNOX_PASSWORD=&quot;Test123#&quot; export DOCKER_REGISTRY=&quot;private-repo.microsoft.com&quot; export DOCKER_REPOSITORY=&quot;mssql-private-preview&quot; export DOCKER_USERNAME=&quot;docker-email@something.comm&quot; export DOCKER_PASSWORD=&quot;docker-password&quot; export DOCKER_EMAIL=&quot;docker-email@something.com&quot; export DOCKER_PRIVATE_REGISTRY=&quot;1&quot; mssqlctl create cluster &amp;lt;CLUSTER_NAME&amp;gt; Let’s start easy by creating our SQL Server Big Data Cluster, this will deploy the complete cluster on the AKS cluster we created earlier. It will look like this: 2019-01-16 09:30:35.0826 UTC | INFO | Creating cluster... 2019-01-16 09:30:37.0313 UTC | INFO | Deploying controller... 2019-01-16 09:30:39.0764 UTC | INFO | The service account token is ready for controller 2019-01-16 09:30:41.0613 UTC | INFO | Waiting for controller pod to be up... ... it takes a while ... 2019-01-16 09:39:40.0930 UTC | INFO | Waiting for controller pod to be up... 2019-01-16 09:39:46.0337 UTC | INFO | Controller pod is running. 2019-01-16 09:39:46.0542 UTC | INFO | Controller Endpoint: https://11.22.33.44:30080 2019-01-16 09:43:15.0898 UTC | INFO | Deployment progress can be tracked at Portal Endpoint: https://11.22.33.44:30777/portal/ 2019-01-16 09:43:15.0905 UTC | INFO | Deploying cluster... 2019-01-16 09:43:16.0627 UTC | INFO | Cluster monitoring is ready. 2019-01-16 09:43:16.0627 UTC | INFO | Initiating cluster creation. 2019-01-16 09:43:16.0628 UTC | INFO | Creating cluster with name: sql-server-cluster 2019-01-16 09:56:14.0388 UTC | INFO | Control plane is ready. 2019-01-16 10:02:38.0710 UTC | INFO | Storage pool is ready. 2019-01-16 10:02:38.0711 UTC | INFO | Data pool is ready. 2019-01-16 10:03:06.0027 UTC | INFO | Master pool is ready. 2019-01-16 10:03:23.0044 UTC | INFO | Compute pool is ready. 2019-01-16 10:03:24.0355 UTC | INFO | Cluster state: Ready 2019-01-16 10:03:24.0355 UTC | INFO | Monitor and track your cluster at the Portal Endpoint: https://11.22.33.44:30777/portal/ 2019-01-16 10:03:24.0356 UTC | INFO | Cluster deployed successfully. Allowing you to login on the your cluster! Display Information about our cluster Let’s see how we can get the information to login on our cluster through commands for automation: # Note: view detailed info through `kubectl get service kubernetes -o json` # Get endpoint-master-pool # e.g. kubectl get svc endpoint-master-pool -n sql-server-cluster -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot; kubectl get service endpoint-master-pool -n &amp;lt;CLUSTER_NAME&amp;gt; -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot; # Get Service Security Loadbalancer # e.g. kubectl get svc service-security-lb -n sql-server-cluster -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot; kubectl get service service-security-lb -n &amp;lt;CLUSTER_NAME&amp;gt; -o=custom-columns=&quot;&quot;IP:status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot; # Cluster Admin Portal # e.g. kubectl get svc service-proxy-lb -n sql-server-cluster -o=custom-columns=&quot;&quot;IP:.status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot; kubectl get service service-proxy-lb -n &amp;lt;CLUSTER_NAME&amp;gt; -o=custom-columns=&quot;&quot;IP:status.loadBalancer.ingress[0].ip,PORT:.spec.ports[0].port&quot;&quot; We can now open our Azure Data Studio and login on our clusters: SQL: IP and PORT received from endpoint-master-pool (use &amp;lt;IP&amp;gt;,&amp;lt;PORT&amp;gt; format in Data Studio) Spark/HDFS: IP received from service-security-lb (no port required on connection) Note: For Spark/HDFS we use username: root, password: &amp;lt;your_password&amp;gt; Note: For SQL we use username: sa, password: &amp;lt;your_sa_password&amp;gt;</summary></entry><entry><title type="html">Quantum Computing - A Linear Algebra Refresher</title><link href="/quantum-linear-algebra" rel="alternate" type="text/html" title="Quantum Computing - A Linear Algebra Refresher" /><published>2019-01-16T09:00:00+00:00</published><updated>2019-01-16T09:00:00+00:00</updated><id>/quantum-linear-algebra</id><content type="html" xml:base="/quantum-linear-algebra">&lt;p&gt;Quantum requires a lot of Linear Algebra, so much even that it’s very interesting to have a quick reminder about it. In here I will explain the basics of Linear Algebra that are needed to work with Quantum Computing.&lt;/p&gt;

&lt;h2 id=&quot;basic-concepts&quot;&gt;Basic Concepts&lt;/h2&gt;

&lt;p&gt;Most often used in Quantum Computing are the so called “Ket” vectors, which are a representation of the “Dirac Notation”.&lt;/p&gt;

&lt;p&gt;These vectors can look like: $&amp;lt;\phi|\psi&amp;gt;$ where we have several elements:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt; x&lt;/code&gt; = Our “bra”, mostly representing a row vector&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt;   = Action of a linear functional on a vector or the scalar product of vectors&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;y &amp;gt;&lt;/code&gt; = our “ket”, mostly representing a column vector&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;matrices&quot;&gt;Matrices&lt;/h2&gt;

&lt;p&gt;A matrix is a rectangular scheme of numbers with &lt;code class=&quot;highlighter-rouge&quot;&gt;m rows&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;x columns&lt;/code&gt;. It is an easy way to calculate formulas that are represented in some sort of structure. Most commonly used in Quantum Computing is the need for being able to Multiply these matrices. However to be able to multiple these matrices, we first need to look if the &lt;em&gt;base requirement of the columns of matrix a being equal to the rows of matrix b&lt;/em&gt; is met. Once that is done, we can start multiplying them.&lt;/p&gt;

&lt;p&gt;To multiple those, we then take every row and multiply it with every column, taking the sum of the results.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
a &amp; b \\
c &amp; d
\end{bmatrix}

\begin{bmatrix}
x \\
y
\end{bmatrix}

=

\begin{bmatrix}
ax + by \\
cx + dy
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;blockquote&gt;
  &lt;p&gt;Notice that our first matrix is a 2 x 2 matrix, and our second one is a 2 x 1 –&amp;gt; 2 x &lt;strong&gt;2&lt;/strong&gt; &amp;amp; &lt;strong&gt;2&lt;/strong&gt; x 1, the insides 2’s have to be equal.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Putting this into practice:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
3 &amp; 4 &amp; 5 \\
6 &amp; 7 &amp; 8
\end{bmatrix}

\begin{bmatrix}
0 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 0
\end{bmatrix}

=

\begin{bmatrix}
1*0+2*0+3*1 &amp; 1*0+2*1+3*0 &amp; 1*1+2*0+3*0 \\
4*0+5*0+6*1 &amp; 4*0+5*1+6*0 &amp; 4*1+5*0+6*0 \\
7*0+8*0+9*1 &amp; 7*0+8*1+9*0 &amp; 7*1+8*0+9*0
\end{bmatrix}

=

\begin{bmatrix}
3 &amp; 2 &amp; 1 \\
6 &amp; 5 &amp; 4 \\
9 &amp; 8 &amp; 7
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;complex-numbers&quot;&gt;Complex Numbers&lt;/h2&gt;

&lt;p&gt;Complex numbers are written by $i$, they solve the fundamental problem of $\sqrt{-1}$ which is impossible to solve, stating it as a new symbol $i$.&lt;/p&gt;

&lt;p&gt;We can visualize complex numbers by using a circle of unit length 1, generating an Imaginary axis and a Real axis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/quantum/linear-algebra/complex-numbers2.png&quot; alt=&quot;/assets/images/posts/quantum/linear-algebra/complex-numbers2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where we can find the following statements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$z = x + y*i$&lt;/li&gt;
  &lt;li&gt;$z= e^{j\theta}$&lt;/li&gt;
  &lt;li&gt;$z = \mid z \mid * (cos(\theta) + i*sin(\theta))$&lt;/li&gt;
  &lt;li&gt;$\mid z \mid = \sqrt{x^2 + y^2}$&lt;/li&gt;
  &lt;li&gt;$\theta = tg^{-1}(\frac{y}{x})$&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Xavier Geerinck</name></author><category term="quantum" /><summary type="html">Quantum requires a lot of Linear Algebra, so much even that it’s very interesting to have a quick reminder about it. In here I will explain the basics of Linear Algebra that are needed to work with Quantum Computing. Basic Concepts Most often used in Quantum Computing are the so called “Ket” vectors, which are a representation of the “Dirac Notation”. These vectors can look like: $&amp;lt;\phi|\psi&amp;gt;$ where we have several elements: &amp;lt; x = Our “bra”, mostly representing a row vector | = Action of a linear functional on a vector or the scalar product of vectors y &amp;gt; = our “ket”, mostly representing a column vector Matrices A matrix is a rectangular scheme of numbers with m rows and x columns. It is an easy way to calculate formulas that are represented in some sort of structure. Most commonly used in Quantum Computing is the need for being able to Multiply these matrices. However to be able to multiple these matrices, we first need to look if the base requirement of the columns of matrix a being equal to the rows of matrix b is met. Once that is done, we can start multiplying them. To multiple those, we then take every row and multiply it with every column, taking the sum of the results. Example: Notice that our first matrix is a 2 x 2 matrix, and our second one is a 2 x 1 –&amp;gt; 2 x 2 &amp;amp; 2 x 1, the insides 2’s have to be equal. Putting this into practice: Complex Numbers Complex numbers are written by $i$, they solve the fundamental problem of $\sqrt{-1}$ which is impossible to solve, stating it as a new symbol $i$. We can visualize complex numbers by using a circle of unit length 1, generating an Imaginary axis and a Real axis. Where we can find the following statements: $z = x + y*i$ $z= e^{j\theta}$ $z = \mid z \mid * (cos(\theta) + i*sin(\theta))$ $\mid z \mid = \sqrt{x^2 + y^2}$ $\theta = tg^{-1}(\frac{y}{x})$</summary></entry></feed>